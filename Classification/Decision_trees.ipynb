{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing binary decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load the titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/matteoamadei/Desktop/CORSOMACHINELEARNING/train_sf.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/matteoamadei/Desktop/CORSOMACHINELEARNING/train_sf.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.040629 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.040629 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,int,str,int,int,int,int,str,float,str,str,int,int,int,int,int,int,int,int,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/matteoamadei/Desktop/CORSOMACHINELEARNING/train_sf.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/matteoamadei/Desktop/CORSOMACHINELEARNING/train_sf.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 714 lines in 0.014667 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 714 lines in 0.014667 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = graphlab.SFrame('train_sf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">PassengerId</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Survived</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Pclass</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Sex</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Age</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">SibSp</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Parch</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Braund, Mr. Owen Harris</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cumings, Mrs. John<br>Bradley (Florence Briggs ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Heikkinen, Miss. Laina</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Futrelle, Mrs. Jacques<br>Heath (Lily May Peel) ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Allen, Mr. William Henry</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">McCarthy, Mr. Timothy J</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">17463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Palsson, Master. Gosta<br>Leonard ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">349909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Johnson, Mrs. Oscar W<br>(Elisabeth Vilhelmina ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">347742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nasser, Mrs. Nicholas<br>(Adele Achem) ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">237736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Sandstrom, Miss.<br>Marguerite Rut ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">PP 9549</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Fare</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Cabin</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Embarked</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Has_Cabin</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">FamilySize</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">IsAlone</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">2</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">3</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">C</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Q</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.25</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">71.2833</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C85</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.925</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">53.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C123</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.05</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">51.8625</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">E46</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">21.075</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11.1333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">30.0708</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">nan</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16.7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">G6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[714 rows x 21 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tPassengerId\tint\n",
       "\tSurvived\tint\n",
       "\tPclass\tint\n",
       "\tName\tstr\n",
       "\tSex\tint\n",
       "\tAge\tint\n",
       "\tSibSp\tint\n",
       "\tParch\tint\n",
       "\tTicket\tstr\n",
       "\tFare\tfloat\n",
       "\tCabin\tstr\n",
       "\tEmbarked\tstr\n",
       "\tHas_Cabin\tint\n",
       "\tFamilySize\tint\n",
       "\tIsAlone\tint\n",
       "\t1\tint\n",
       "\t2\tint\n",
       "\t3\tint\n",
       "\tC\tint\n",
       "\tQ\tint\n",
       "\tS\tint\n",
       "\n",
       "Rows: 714\n",
       "\n",
       "Data:\n",
       "+-------------+----------+--------+--------------------------------+-----+-----+\n",
       "| PassengerId | Survived | Pclass |              Name              | Sex | Age |\n",
       "+-------------+----------+--------+--------------------------------+-----+-----+\n",
       "|      1      |    0     |   3    |    Braund, Mr. Owen Harris     |  0  |  1  |\n",
       "|      2      |    1     |   1    | Cumings, Mrs. John Bradley...  |  1  |  1  |\n",
       "|      3      |    1     |   3    |     Heikkinen, Miss. Laina     |  1  |  1  |\n",
       "|      4      |    1     |   1    | Futrelle, Mrs. Jacques Hea...  |  1  |  1  |\n",
       "|      5      |    0     |   3    |    Allen, Mr. William Henry    |  0  |  1  |\n",
       "|      7      |    0     |   1    |    McCarthy, Mr. Timothy J     |  0  |  1  |\n",
       "|      8      |    0     |   3    | Palsson, Master. Gosta Leonard |  0  |  0  |\n",
       "|      9      |    1     |   3    | Johnson, Mrs. Oscar W (Eli...  |  1  |  1  |\n",
       "|      10     |    1     |   2    | Nasser, Mrs. Nicholas (Ade...  |  1  |  0  |\n",
       "|      11     |    1     |   3    | Sandstrom, Miss. Marguerit...  |  1  |  0  |\n",
       "+-------------+----------+--------+--------------------------------+-----+-----+\n",
       "+-------+-------+------------------+---------+-------+----------+-----------+------------+\n",
       "| SibSp | Parch |      Ticket      |   Fare  | Cabin | Embarked | Has_Cabin | FamilySize |\n",
       "+-------+-------+------------------+---------+-------+----------+-----------+------------+\n",
       "|   1   |   0   |    A/5 21171     |   7.25  |  nan  |    S     |     0     |     2      |\n",
       "|   1   |   0   |     PC 17599     | 71.2833 |  C85  |    C     |     1     |     2      |\n",
       "|   0   |   0   | STON/O2. 3101282 |  7.925  |  nan  |    S     |     0     |     1      |\n",
       "|   1   |   0   |      113803      |   53.1  |  C123 |    S     |     1     |     2      |\n",
       "|   0   |   0   |      373450      |   8.05  |  nan  |    S     |     0     |     1      |\n",
       "|   0   |   0   |      17463       | 51.8625 |  E46  |    S     |     1     |     1      |\n",
       "|   3   |   1   |      349909      |  21.075 |  nan  |    S     |     0     |     5      |\n",
       "|   0   |   2   |      347742      | 11.1333 |  nan  |    S     |     0     |     3      |\n",
       "|   1   |   0   |      237736      | 30.0708 |  nan  |    C     |     0     |     2      |\n",
       "|   1   |   1   |     PP 9549      |   16.7  |   G6  |    S     |     1     |     3      |\n",
       "+-------+-------+------------------+---------+-------+----------+-----------+------------+\n",
       "+---------+---+---+---+---+---+-----+\n",
       "| IsAlone | 1 | 2 | 3 | C | Q | ... |\n",
       "+---------+---+---+---+---+---+-----+\n",
       "|    0    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "|    0    | 1 | 0 | 0 | 1 | 0 | ... |\n",
       "|    1    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "|    0    | 1 | 0 | 0 | 0 | 0 | ... |\n",
       "|    1    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "|    1    | 1 | 0 | 0 | 0 | 0 | ... |\n",
       "|    0    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "|    0    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "|    0    | 0 | 1 | 0 | 1 | 0 | ... |\n",
       "|    0    | 0 | 0 | 1 | 0 | 0 | ... |\n",
       "+---------+---+---+---+---+---+-----+\n",
       "[714 rows x 21 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['Survived'] = train['Survived'].apply(lambda x : +1 if x==1 else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train.random_split(0.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['Sex',\n",
    "            'Age',            \n",
    "            'Has_Cabin',     \n",
    "            'IsAlone',\n",
    "            '1', #1 classe\n",
    "            '2', #2 classe\n",
    "            '3', #3 classe\n",
    "            'C',\n",
    "            'Q',\n",
    "            'S'\n",
    "           ]\n",
    "target = 'Survived'\n",
    "\n",
    "titanic = train_data[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def node_num_mistakes(labels):\n",
    "    # Se labels_in node è empty ritorna zero\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Conta il numero labels = -1\n",
    "    negative = sum([x == -1 for x in labels])\n",
    "    \n",
    "    # Conta il numero di labels = +1\n",
    "    positive = sum([x == 1 for x in labels])\n",
    "\n",
    "    #Siccome stiamo calcolando il majority  class prediction, tutti i datapoint che non sono \n",
    "    #nel majority class sono errori\n",
    "    # Ritorna il numero di errori del majority classifier. \n",
    "    return min(positive, negative)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n",
      "Test passed!\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test case 1\n",
    "example_labels = graphlab.SArray([-1, -1, 1, 1, 1])\n",
    "if node_num_mistakes(example_labels) == 2:\n",
    "    print 'ok!'\n",
    "else:\n",
    "    print 'non corretto'\n",
    "\n",
    "# Test case 2\n",
    "example_labels = graphlab.SArray([-1, -1, 1, 1, 1, 1, 1])\n",
    "if node_num_mistakes(example_labels) == 2:\n",
    "    print 'ok!'\n",
    "else:\n",
    "    print 'non corretto'\n",
    "    \n",
    "# Test case 3\n",
    "example_labels = graphlab.SArray([-1, -1, -1, -1, -1, 1, 1])\n",
    "if node_num_mistakes(example_labels) == 2:\n",
    "    print 'ok!'\n",
    "else:\n",
    "    print 'non corretto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trovare la migliore feature su cui fare split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    best_feature = None #seleziona la best feature\n",
    "    #errore è sempre <=1 quindi possiamo inizializzarlo con qualcosa più grande di 1\n",
    "    best_error = 10         \n",
    "    # Iteriamo su ogni feature per considerare lo split su quella feature \n",
    "    for feature in features:\n",
    "        #  Nel left_split memorizziamo tutti i data point dove il valore della feature è 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        #Nel right split memorizziamo tutti i data point dove il valore della feature è 1\n",
    "        right_split =  data[data[feature] == 1]\n",
    "        #Calcoliamo il numero di errori nel left_split utilizzando la funzione node_num_mistakes\n",
    "        left_mistakes = node_num_mistakes(left_split['Survived'])            \n",
    "        #Calcoliamo il numero di errori nel right_split utilizzando la funzione node_num_mistakes\n",
    "        right_mistakes = node_num_mistakes(right_split['Survived'])     \n",
    "        # Calcola il classification error\n",
    "        # Error = (#  errori (left) + # errori (right)) / (# of data points)\n",
    "        error = float(left_mistakes + right_mistakes) / len(data)\n",
    "        # Se è il miglior errore, fai aggiornamento.\n",
    "        if error < best_error:\n",
    "            best_feature, best_error = feature, error\n",
    "    return best_feature # Ritorna la best feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the tree\n",
    "\n",
    "Costruiamo il decision tree. Ogni nodo del decision tree è rappresentato da un dizionario che contiene \n",
    "\n",
    "    { \n",
    "       'is_leaf'            : True/False.\n",
    "       'prediction'         : Predizione al nodo foglia.\n",
    "       'left'               : (dizionario corrispondente all'albero sinistro).\n",
    "       'right'              : (dizionario corrispondente all'albero destro).\n",
    "       'splitting_feature'  : La feature che questo nodo splitta.\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Crea un nodo foglia\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True    }   \n",
    "    \n",
    "    # Conta il numero di data point che sono +1 o -1 \n",
    "    num_positive = len(target_values[target_values == +1])\n",
    "    num_negative = len(target_values[target_values == -1])\n",
    "    \n",
    "    #  Per il nodo foglia imposta la predizione al majority class\n",
    "    if num_positive > num_negative:\n",
    "        leaf['prediction'] = 1       \n",
    "    else:\n",
    "        leaf['prediction'] = -1                 \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n",
    "    remaining_features = features[:]  #Copia le feature\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Sottoalbero, profondità = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "\n",
    "    # Stopping condition 1\n",
    "    #Controlla se ci sono errori al nodo corrente\n",
    "\n",
    "    if node_num_mistakes(target_values) == 0:  \n",
    "        print \"Stopping condition 1 reached.\"     \n",
    "        # Se non ci sono errori al nodo corrente, rendilo una foglia\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2 (Controlla se ci sono feature su cui splittare )\n",
    "    if remaining_features == []:   \n",
    "        print \"Stopping condition 2 reached.\"    \n",
    "        # il nodo corrente è un nodo foglia\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # max_depth\n",
    "    if current_depth >= max_depth:  \n",
    "        print \"Raggiunta max depth. Stopping for now.\"\n",
    "        # Se è stata raggiunta la massima profondità, stopping condition\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    #  Trova la migliore feature su cui fare split\n",
    "    splitting_feature = best_splitting_feature(data, remaining_features, 'Survived')\n",
    "    # Fai lo split sulla best feature trovata\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]       \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print \"Split su %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    # Crea un nodo foglia se lo split è perfetto \n",
    "    if len(left_split) == len(data):\n",
    "        print \"Crea foglia.\"\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print \"Crea foglia\"\n",
    "        return create_leaf(right_split[target])        \n",
    "    # Ripeti sui sottoalberi destro e sinistro. \n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione ricorsiva per contare i nodi nel tuo albero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (572 data points).\n",
      "Split on feature Sex. (369, 203)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (369 data points).\n",
      "Split on feature Age. (42, 327)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (42 data points).\n",
      "Split on feature 3. (11, 31)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (11 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (31 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (327 data points).\n",
      "Split on feature Has_Cabin. (251, 76)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (251 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (76 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (203 data points).\n",
      "Split on feature 3. (120, 83)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (120 data points).\n",
      "Split on feature Age. (13, 107)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (13 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (107 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (83 data points).\n",
      "Split on feature C. (68, 15)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (68 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (15 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree = decision_tree_create(titanic, features, 'Survived', max_depth = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # se il nodo è una foglia\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print \"Alla foglia, predici %s\" % tree['prediction']\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print \"Split su %s = %s\" % (tree['splitting_feature'], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            if annotate:\n",
    "                print 'left split'\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            if annotate:\n",
    "                print 'right split'\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '2': 1,\n",
       " '3': 0,\n",
       " 'Age': 0,\n",
       " 'C': 1,\n",
       " 'Cabin': 'nan',\n",
       " 'Embarked': 'C',\n",
       " 'FamilySize': 2,\n",
       " 'Fare': 30.0708,\n",
       " 'Has_Cabin': 0,\n",
       " 'IsAlone': 0,\n",
       " 'Name': 'Nasser, Mrs. Nicholas (Adele Achem)',\n",
       " 'Parch': 0,\n",
       " 'PassengerId': 10,\n",
       " 'Pclass': 2,\n",
       " 'Q': 0,\n",
       " 'S': 0,\n",
       " 'Sex': 1,\n",
       " 'SibSp': 1,\n",
       " 'Survived': 1,\n",
       " 'Ticket': '237736'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print 'Classe predetta: %s ' % classify(my_decision_tree, test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some annotations to our prediction to see what the prediction path was that lead to this predicted class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split su Sex = 1\n",
      "right split\n",
      "Split su 3 = 0\n",
      "left split\n",
      "Split su Age = 0\n",
      "left split\n",
      "Alla foglia, predici 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree, test_data[0], annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Fai prediction per ogni riga\n",
    "    prediction = data.apply(lambda x: classify(tree, x))    \n",
    "#Calcola il classification error   \n",
    "    return (prediction != data['Survived']).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18309859154929578"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stampa un decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name è ad esempio age\n",
    "    if split_name is None:\n",
    "        print \"(leaf, label: %s)\" % tree['prediction']\n",
    "        return None\n",
    "    print '                       %s' % name\n",
    "    print '         |---------------|----------------|'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '  [{0} == 0]               [{0} == 1]    '.format(split_name)\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [Sex == 0]               [Sex == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exploring the intermediate left subtree\n",
    "\n",
    "* `my_decision_tree['left']` per andare a sinistra \n",
    "* `my_decision_tree['right']` per andare a destra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Sex\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [Age == 0]               [Age == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left->Left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Age\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [3 == 0]               [3 == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: 1)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left']['left'], my_decision_tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Age\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [Has_Cabin == 0]               [Has_Cabin == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left']['right'], my_decision_tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Sex\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [3 == 0]               [3 == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['right'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Right->Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       3\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [C == 0]               [C == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                         (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['right']['right'], my_decision_tree['right']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       3\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [Age == 0]               [Age == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: 1)                         (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['right']['left'], my_decision_tree['right']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ADA BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Somma tutti i pesi delle label positive\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Peso errore per -1 è uguale alla somma dei pesi dei positivi\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Somma tutti i pesi delle label negative\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    # Peso errore per +1 è uguale alla somma dei pesi dei negativi\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    #Ritorna il peso minore tra i due pesi. \n",
    "    if weighted_mistakes_all_positive <= weighted_mistakes_all_negative:\n",
    "        return weighted_mistakes_all_positive, +1\n",
    "    else:\n",
    "        return weighted_mistakes_all_negative, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature_boost(data, features, target, data_weights):\n",
    "    print data_weights\n",
    "    \n",
    "    # Feature che tengono traccia della migliore feature e del migliore errore\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    # Loop su ogni feature\n",
    "    for feature in features:\n",
    "        # Left, feature =0\n",
    "        # Right feature= 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        # Applico  filtro a  data_weights per creare left_data_weights, right_data_weights\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "            \n",
    "        # Calcola il peso degli errori per left e right \n",
    "        left_weighted_mistakes, left_class = node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        # Calcola errore pesato\n",
    "        #  ( [weight of mistakes (left)] + [weight of mistakes (right)] ) / [total weight of all data points]\n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes) / (sum(left_data_weights) + sum(right_data_weights))\n",
    "        \n",
    "        # Se è il miglior errore, salva la feature e l'errore\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    # Ritorna la migliore feature\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Crea un nodo foglia\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    # Calcola il peso degli errori\n",
    "    weighted_error, best_class = node_weighted_mistakes(target_values, data_weights)\n",
    "    # Memorizza la classe predetta\n",
    "    leaf['prediction'] = best_class \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 3):\n",
    "    remaining_features = features[:] # Fai una copia delle feature\n",
    "    target_values = data[target]\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Sottoalbero, profondità = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    # Stopping condition 1. Attenzione, sono pesi, abbiamo bisogno di una soglia!!\n",
    "    if node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print \"Stopping condition 1 .\"                \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. Non ci sono più features.\n",
    "    if remaining_features == []:\n",
    "        print \"Stopping condition 2.\"                \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Max_depth\n",
    "    if current_depth > max_depth:\n",
    "        print \"Raggiunta massima profondità.\"\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Se tutti i datapoint appartengono alla stessa classe, crea una foglia\n",
    "    splitting_feature = best_splitting_feature_boost(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print \"Split su feature %s. (%s, %s)\" % (\\\n",
    "              splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    # Crea una foglia se lo split è perfettol\n",
    "    if len(left_split) == len(data):\n",
    "        print \"Crea nodo foglia.\"\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print \"Crea nodo foglia.\"\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Fai ricorsione sui sub_trees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[ 0.72467147  0.42471509  0.37703988  0.63775391  0.37776725  0.79872089\n",
      "  0.27369329  0.4703735   0.52427341  0.04669385  0.81443818  0.92632238\n",
      "  0.11366561  0.03967887  0.08654353  0.95033428  0.02552969  0.9979868\n",
      "  0.43061829  0.45886651  0.77229004  0.02145871  0.43772729  0.47343555\n",
      "  0.72514099  0.26778839  0.64487751  0.8187038   0.86402442  0.83450133\n",
      "  0.98011175  0.74119745  0.94608064  0.13882146  0.3281539   0.03763578\n",
      "  0.52365205  0.52256546  0.58535752  0.89538643  0.47550451  0.05519968\n",
      "  0.84777816  0.92818268  0.34415312  0.8436549   0.75557451  0.11250183\n",
      "  0.72143619  0.1491032   0.77655732  0.18774885  0.30413586  0.32597063\n",
      "  0.03803729  0.25455503  0.16709128  0.87995648  0.86387658  0.48267653\n",
      "  0.98386388  0.17716998  0.10797871  0.82352857  0.96427417  0.398303\n",
      "  0.46471141  0.90657038  0.73793512  0.32986128  0.29254479  0.14106917\n",
      "  0.19255682  0.84605637  0.75599603  0.42921928  0.01066099  0.03573099\n",
      "  0.8858463   0.68129445  0.71597821  0.31015777  0.29611413  0.07759832\n",
      "  0.96014732  0.02153183  0.71357824  0.12156157  0.57169803  0.04933304\n",
      "  0.42143266  0.52488333  0.74932011  0.80177791  0.33919809  0.88378853\n",
      "  0.05062318  0.01846409  0.76890253  0.46985075  0.21336913  0.46155114\n",
      "  0.83222526  0.81805136  0.88201647  0.18319043  0.01601872  0.94138998\n",
      "  0.26875164  0.49784375  0.55618451  0.8707347   0.56638174  0.89472652\n",
      "  0.88050973  0.47825756  0.12340642  0.08707748  0.52942549  0.20053588\n",
      "  0.87403652  0.58985299  0.48931388  0.8406224   0.24048165  0.34892097\n",
      "  0.11964727  0.59501724  0.96419853  0.69357757  0.22243212  0.99787424\n",
      "  0.75313063  0.69900015  0.88828988  0.97559079  0.18179266  0.6416734\n",
      "  0.1410663   0.3116252   0.25978703  0.68820663  0.21794385  0.85443615\n",
      "  0.78711475  0.31719676  0.52175122  0.85216262  0.01303436  0.99209679\n",
      "  0.69352451  0.69147863  0.22939058  0.47357097  0.87206174  0.30726509\n",
      "  0.35810267  0.03769394  0.71375678  0.38376489  0.38760696  0.82596475\n",
      "  0.10332568  0.27733095  0.43353498  0.0762431   0.63618149  0.93570456\n",
      "  0.02669982  0.11316146  0.12429154  0.07154484  0.13573481  0.12778917\n",
      "  0.5178193   0.09146133  0.99029363  0.23057065  0.91658624  0.82395419\n",
      "  0.64472856  0.09392072  0.34093644  0.12242706  0.70975175  0.51196428\n",
      "  0.05620287  0.2552118   0.96474715  0.94842924  0.29469529  0.41894513\n",
      "  0.03986746  0.7916893   0.31670167  0.0995277   0.63416741  0.77697827\n",
      "  0.20333216  0.92891     0.50002569  0.0862143   0.20392926  0.26143649\n",
      "  0.2754122   0.36763135  0.76835256  0.17806566  0.67846819  0.00380574\n",
      "  0.79831962  0.98974881  0.61509856  0.96645423  0.09506575  0.16724203\n",
      "  0.78837773  0.77193764  0.67970969  0.38580639  0.07233691  0.36950135\n",
      "  0.13244202  0.98092314  0.81560968  0.27501456  0.38639941  0.80593189\n",
      "  0.47948962  0.12883106  0.1063859   0.47269781  0.58049145  0.93742248\n",
      "  0.41473577  0.61399395  0.95519387  0.0872521   0.28797265  0.83812629\n",
      "  0.78538335  0.81805525  0.56502697  0.7406993   0.57427726  0.76537176\n",
      "  0.09145463  0.64326186  0.75981525  0.83045043  0.85031413  0.57335996\n",
      "  0.98412866  0.5157758   0.55119251  0.78779377  0.52809025  0.20215224\n",
      "  0.4259596   0.41285084  0.43711765  0.58557392  0.60219675  0.12311737\n",
      "  0.44342917  0.6379892   0.77453096  0.63075571  0.48608029  0.19865991\n",
      "  0.59530801  0.5082459   0.40816247  0.06038873  0.07849871  0.96924076\n",
      "  0.06900877  0.61294537  0.8814664   0.46208861  0.85554848  0.62006041\n",
      "  0.86874443  0.49443464  0.53437953  0.91479914  0.08769265  0.45971121\n",
      "  0.93235428  0.26559585  0.88244133  0.72579756  0.55657719  0.06544584\n",
      "  0.87846203  0.06173162  0.92195967  0.95952601  0.2335743   0.52702358\n",
      "  0.76499572  0.54258422  0.27851975  0.47882597  0.9161235   0.60061345\n",
      "  0.64675999  0.05186733  0.34996442  0.12881429  0.59013536  0.93758936\n",
      "  0.0850399   0.26273721  0.74491119  0.57048503  0.17610259  0.97220185\n",
      "  0.38060423  0.8818965   0.37827239  0.78739282  0.25604033  0.33570093\n",
      "  0.63282699  0.2021724   0.30944102  0.10224064  0.11852863  0.40709127\n",
      "  0.44210181  0.90711694  0.08948974  0.00986056  0.33516354  0.93774674\n",
      "  0.18854009  0.67059035  0.47733654  0.05926691  0.0103653   0.04067827\n",
      "  0.67967081  0.652301    0.96882233  0.62232174  0.43084644  0.50812331\n",
      "  0.81059594  0.94065721  0.75144589  0.97963295  0.12757305  0.62238616\n",
      "  0.9372369   0.33631744  0.97822732  0.28661616  0.91637739  0.74344036\n",
      "  0.89662138  0.50024804  0.39233887  0.63656134  0.12829634  0.98236237\n",
      "  0.75628173  0.90770207  0.73529839  0.77150715  0.43740732  0.65502028\n",
      "  0.41054441  0.3019527   0.40578029  0.55550664  0.81393701  0.89766952\n",
      "  0.86553073  0.85180062  0.03813417  0.00227005  0.29318422  0.56025971\n",
      "  0.06969513  0.6164841   0.60780203  0.12180366  0.7940265   0.8477495\n",
      "  0.73451589  0.16178492  0.02120022  0.90875346  0.50075148  0.55239037\n",
      "  0.31331931  0.31878913  0.51704854  0.45283601  0.65638128  0.95310695\n",
      "  0.38350248  0.80253024  0.48497134  0.30394753  0.88922163  0.99379067\n",
      "  0.60493343  0.14519178  0.44452947  0.51566927  0.05849471  0.51754264\n",
      "  0.55363034  0.22855428  0.79119892  0.73832836  0.99949062  0.36006447\n",
      "  0.6906223   0.02990745  0.79204446  0.45822624  0.94921892  0.68721502\n",
      "  0.24200566  0.29800748  0.0658196   0.8085638   0.87413179  0.66622751\n",
      "  0.97541085  0.69268406  0.37691241  0.93146251  0.63914856  0.51744921\n",
      "  0.35389166  0.11749594  0.40227285  0.18298139  0.58379526  0.45860771\n",
      "  0.47672063  0.35307407  0.82239263  0.86748827  0.74930053  0.95170895\n",
      "  0.51498247  0.82075128  0.60911183  0.69325177  0.49782749  0.33612047\n",
      "  0.29436484  0.70308934  0.0867094   0.20340717  0.74402614  0.06403436\n",
      "  0.21772199  0.71361732  0.18280789  0.24109471  0.40912301  0.65993003\n",
      "  0.22931345  0.69522118  0.57311914  0.6235668   0.6838723   0.29601753\n",
      "  0.25405138  0.04096014  0.78201243  0.33004506  0.39557682  0.83503242\n",
      "  0.10365751  0.7255691   0.54413058  0.168002    0.56582283  0.4864651\n",
      "  0.40181343  0.75814007  0.49655895  0.15750653  0.36518693  0.40921616\n",
      "  0.93951392  0.3181105   0.61800192  0.70932986  0.33738521  0.50810383\n",
      "  0.25918828  0.21595682  0.73212527  0.81269752  0.55858075  0.86311077\n",
      "  0.82093632  0.52641891  0.85140166  0.2654405   0.427305    0.81816826\n",
      "  0.46062968  0.61026719  0.66256287  0.31743801  0.75598926  0.63087976\n",
      "  0.91936411  0.55758498  0.84838498  0.97057402  0.77707177  0.69490691\n",
      "  0.63148848  0.27431019  0.64976732  0.85749182  0.67284177  0.77917083\n",
      "  0.66583283  0.12889248  0.34834125  0.96106967  0.73099825  0.34479098\n",
      "  0.2749159   0.35953851  0.25431592  0.17963903  0.4686434   0.86488161\n",
      "  0.87343846  0.23361295  0.87029798  0.48501089  0.82156127  0.39376035\n",
      "  0.27335889  0.63060189  0.46374994  0.74146021  0.21615926  0.96873159\n",
      "  0.57113588  0.29544852  0.95293465  0.36504297  0.65210353  0.82043561\n",
      "  0.11368768  0.05454757  0.84203792  0.28455524  0.42718765  0.52335205\n",
      "  0.94743308  0.37970255  0.5216446   0.36616326  0.12764438  0.52621174\n",
      "  0.77876501  0.86496631]\n",
      "Split on feature Q. (552, 20)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (552 data points).\n",
      "[ 0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.72467147  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509  0.72467147\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.72467147  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509  0.72467147\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.72467147\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.72467147  0.42471509  0.42471509\n",
      "  0.42471509  0.72467147]\n",
      "Split on feature Age. (78, 474)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (78 data points).\n",
      "[ 0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509]\n",
      "Split on feature IsAlone. (68, 10)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (68 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (10 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (474 data points).\n",
      "[ 0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509\n",
      "  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509  0.42471509]\n",
      "Split on feature C. (382, 92)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (382 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (92 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20 data points).\n",
      "[ 0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.42471509  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147  0.42471509\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.42471509  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147  0.42471509\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.42471509\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.42471509  0.72467147  0.72467147\n",
      "  0.72467147  0.42471509]\n",
      "Split on feature Age. (5, 15)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "[ 0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147]\n",
      "Split on feature Has_Cabin. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (15 data points).\n",
      "[ 0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147  0.72467147\n",
      "  0.72467147  0.72467147]\n",
      "Split on feature Sex. (9, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (9 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (6 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "sample_random = np.random.uniform(low=0.0, high=1, size=(572,))\n",
    "random_data_decision_tree = weighted_decision_tree_create(train_data, features, target,\n",
    "                                        sample_random, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature Sex. (369, 203)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (369 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature Age. (42, 327)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (42 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Split on feature 3. (11, 31)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (31 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (327 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature Has_Cabin. (251, 76)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (251 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (76 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (203 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature 3. (120, 83)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (120 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature Age. (13, 107)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (13 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (107 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (83 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Split on feature C. (68, 15)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (68 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (15 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "example_data_weights = graphlab.SArray([1.0 for i in range(len(train_data))])\n",
    "print len(example_data_weights)\n",
    "small_data_decision_tree = weighted_decision_tree_create(train_data, features, target,\n",
    "                                        example_data_weights, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Applica classify (tree, x) a ogni riga\n",
    "    prediction = data.apply(lambda x: classify(tree, x))\n",
    "    # Una volta che hai fatto le prediction, calcola il classification error. \n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18309859154929578"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5845070422535211"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(random_data_decision_tree, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementare ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # inizialmente tutti gli alpha valgono 1\n",
    "    alpha = graphlab.SArray([1.]*len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    for t in range(num_tree_stumps):\n",
    "        print '====================================================='\n",
    "        print 'Adaboost Iteration %d' % t\n",
    "        print '====================================================='        \n",
    "        #  Apprendi un tree stump. Usa max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        # Fai la prediction\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x))\n",
    "        \n",
    "        # Valuta se ogni valore è predetto correttamente o no\n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "        # Calcola weighted error\n",
    "        weighted_error = sum(alpha * is_wrong) / sum(alpha)\n",
    "        # Calcola il coefficiente del modello usando  weighted error\n",
    "        weight = .5 * log((1 - weighted_error) / weighted_error)\n",
    "        weights.append(weight)\n",
    "        # Modifica i pesi dei datapoint\n",
    "        a_c = is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        # Scala alpha * a_c\n",
    "        ## Normalizza\n",
    "        alpha *= a_c\n",
    "        alpha /= sum(alpha)\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ... ]\n",
      "Split on feature Sex. (369, 203)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (369 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (203 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0039062500000000226, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0011261261261261326, 0.0039062500000000226, ... ]\n",
      "Split on feature 3. (281, 291)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (281 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (291 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0028801245459262916, 0.0008303061754021742, 0.0028801245459262916, 0.001749398644216053, 0.001749398644216053, 0.0028801245459262916, 0.0028801245459262916, 0.001749398644216053, 0.001749398644216053, 0.001749398644216053, 0.001749398644216053, 0.001749398644216053, 0.0008303061754021742, 0.0028801245459262916, 0.001749398644216053, 0.0008303061754021742, 0.001749398644216053, 0.0028801245459262916, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0028801245459262916, 0.001749398644216053, 0.0008303061754021742, 0.006068226547124435, 0.0008303061754021742, 0.0028801245459262916, 0.001749398644216053, 0.0008303061754021742, 0.006068226547124435, 0.001749398644216053, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0028801245459262916, 0.0008303061754021742, 0.001749398644216053, 0.0028801245459262916, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.0008303061754021742, 0.001749398644216053, 0.0028801245459262916, 0.0008303061754021742, 0.0028801245459262916, 0.0028801245459262916, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.001749398644216053, 0.0028801245459262916, 0.001749398644216053, 0.001749398644216053, 0.0008303061754021742, 0.001749398644216053, 0.006068226547124435, 0.006068226547124435, 0.0008303061754021742, 0.0008303061754021742, 0.0028801245459262916, 0.001749398644216053, 0.0008303061754021742, 0.0008303061754021742, 0.001749398644216053, 0.001749398644216053, 0.0008303061754021742, 0.001749398644216053, 0.001749398644216053, 0.0028801245459262916, ... ]\n",
      "Split on feature Has_Cabin. (421, 151)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (421 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (151 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0007267725627504633, 0.0025209923270406694, 0.0007267725627504633, 0.0025209923270406694, 0.001531260363459604, 0.0020400119981712605, 0.0025209923270406694, 0.0025209923270406694, 0.0020400119981712605, 0.0020400119981712605, 0.001531260363459604, 0.001531260363459604, 0.001531260363459604, 0.0007267725627504633, 0.0025209923270406694, 0.0020400119981712605, 0.0009682381803463521, 0.0020400119981712605, 0.0025209923270406694, 0.0007267725627504633, 0.0009682381803463521, 0.0020400119981712605, 0.0009682381803463521, 0.0007267725627504633, 0.0009682381803463521, 0.0007267725627504633, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0025209923270406694, 0.001531260363459604, 0.0007267725627504633, 0.007076291618656561, 0.0009682381803463521, 0.0033585761880764084, 0.0020400119981712605, 0.0007267725627504633, 0.007076291618656561, 0.001531260363459604, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0007267725627504633, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0025209923270406694, 0.0009682381803463521, 0.001531260363459604, 0.0025209923270406694, 0.0020400119981712605, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0007267725627504633, 0.0020400119981712605, 0.0025209923270406694, 0.0007267725627504633, 0.0025209923270406694, 0.0025209923270406694, 0.0007267725627504633, 0.0007267725627504633, 0.001531260363459604, 0.0020400119981712605, 0.0025209923270406694, 0.001531260363459604, 0.001531260363459604, 0.0007267725627504633, 0.0020400119981712605, 0.007076291618656561, 0.007076291618656561, 0.0007267725627504633, 0.0007267725627504633, 0.0025209923270406694, 0.001531260363459604, 0.0007267725627504633, 0.0007267725627504633, 0.0020400119981712605, 0.0020400119981712605, 0.0007267725627504633, 0.001531260363459604, 0.001531260363459604, 0.0025209923270406694, ... ]\n",
      "Split on feature 2. (442, 130)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (442 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (130 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.000826418715060265, 0.0006485706008424454, 0.0018205032429574732, 0.0006485706008424454, 0.000826418715060265, 0.002319713457337919, 0.000826418715060265, 0.0018205032429574732, 0.0006485706008424454, 0.000826418715060265, 0.000826418715060265, 0.0028666399178652944, 0.000826418715060265, 0.0028666399178652944, 0.0013664941480684477, 0.0018205032429574732, 0.0022497292716722322, 0.0028666399178652944, 0.0018205032429574732, 0.002319713457337919, 0.0013664941480684477, 0.0017412080296535571, 0.0017412080296535571, 0.000826418715060265, 0.0028666399178652944, 0.0018205032429574732, 0.0011009911406752696, 0.0018205032429574732, 0.0028666399178652944, 0.000826418715060265, 0.0011009911406752696, 0.002319713457337919, 0.0011009911406752696, 0.000826418715060265, 0.0011009911406752696, 0.000826418715060265, 0.000826418715060265, 0.0006485706008424454, 0.002319713457337919, 0.000826418715060265, 0.000826418715060265, 0.0018205032429574732, 0.000826418715060265, 0.0028666399178652944, 0.0013664941480684477, 0.000826418715060265, 0.006314870624008736, 0.0011009911406752696, 0.003819063019217341, 0.0018205032429574732, 0.000826418715060265, 0.006314870624008736, 0.0017412080296535571, 0.0018205032429574732, 0.000826418715060265, 0.0006485706008424454, 0.000826418715060265, 0.000826418715060265, 0.000826418715060265, 0.002319713457337919, 0.000826418715060265, 0.000826418715060265, 0.002319713457337919, 0.0022497292716722322, 0.0011009911406752696, 0.0013664941480684477, 0.0028666399178652944, 0.002319713457337919, 0.000826418715060265, 0.000826418715060265, 0.0018205032429574732, 0.000826418715060265, 0.002319713457337919, 0.0028666399178652944, 0.000826418715060265, 0.0028666399178652944, 0.0028666399178652944, 0.000826418715060265, 0.000826418715060265, 0.0013664941480684477, 0.002319713457337919, 0.0028666399178652944, 0.0013664941480684477, 0.0013664941480684477, 0.000826418715060265, 0.002319713457337919, 0.006314870624008736, 0.006314870624008736, 0.000826418715060265, 0.000826418715060265, 0.0028666399178652944, 0.0013664941480684477, 0.0006485706008424454, 0.000826418715060265, 0.002319713457337919, 0.0018205032429574732, 0.000826418715060265, 0.0013664941480684477, 0.0013664941480684477, 0.0028666399178652944, ... ]\n",
      "Split on feature Age. (83, 489)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (83 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (489 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007220998513123856, 0.0007580886169388858, 0.0021279144996608473, 0.0007580886169388858, 0.0007220998513123856, 0.0020268959452459886, 0.0009659682691424372, 0.0021279144996608473, 0.0007580886169388858, 0.0007220998513123856, 0.0007220998513123856, 0.0033507024335878294, 0.0009659682691424372, 0.0025047838592398377, 0.0011940015432340672, 0.0015907010539535562, 0.0026296198900067603, 0.0033507024335878294, 0.0021279144996608473, 0.0020268959452459886, 0.0011940015432340672, 0.001521415278240737, 0.001521415278240737, 0.0007220998513123856, 0.0025047838592398377, 0.0015907010539535562, 0.0009620129898920431, 0.0021279144996608473, 0.0025047838592398377, 0.0007220998513123856, 0.0012869051572987336, 0.0020268959452459886, 0.0012869051572987336, 0.0007220998513123856, 0.0009620129898920431, 0.0009659682691424372, 0.0007220998513123856, 0.0007580886169388858, 0.0020268959452459886, 0.0009659682691424372, 0.0009659682691424372, 0.0021279144996608473, 0.0007220998513123856, 0.0033507024335878294, 0.0011940015432340672, 0.0007220998513123856, 0.007381203420698566, 0.0009620129898920431, 0.0033369825586880243, 0.0021279144996608473, 0.0007220998513123856, 0.007381203420698566, 0.001521415278240737, 0.0021279144996608473, 0.0009659682691424372, 0.0007580886169388858, 0.0007220998513123856, 0.0007220998513123856, 0.0007220998513123856, 0.0020268959452459886, 0.0007220998513123856, 0.0007220998513123856, 0.0020268959452459886, 0.0026296198900067603, 0.0012869051572987336, 0.0011940015432340672, 0.0025047838592398377, 0.0020268959452459886, 0.0007220998513123856, 0.0007220998513123856, 0.0021279144996608473, 0.0007220998513123856, 0.0020268959452459886, 0.0033507024335878294, 0.0007220998513123856, 0.0025047838592398377, 0.0025047838592398377, 0.0007220998513123856, 0.0007220998513123856, 0.0011940015432340672, 0.0020268959452459886, 0.0033507024335878294, 0.0011940015432340672, 0.0011940015432340672, 0.0009659682691424372, 0.0020268959452459886, 0.005517744280901399, 0.007381203420698566, 0.0007220998513123856, 0.0007220998513123856, 0.0025047838592398377, 0.0011940015432340672, 0.0007580886169388858, 0.0009659682691424372, 0.0020268959452459886, 0.0021279144996608473, 0.0007220998513123856, 0.0011940015432340672, 0.0011940015432340672, 0.0033507024335878294, ... ]\n",
      "Split on feature Q. (552, 20)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (552 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007748086679502573, 0.0007098020796152977, 0.001992376752999811, 0.0007098020796152977, 0.0007748086679502573, 0.0021748467951566318, 0.0010364779698212217, 0.001992376752999811, 0.0007098020796152977, 0.0007748086679502573, 0.0007748086679502573, 0.0035952829578173623, 0.000904440814648145, 0.002687617566952455, 0.0012811562605398244, 0.0017068123784831546, 0.0024621259636655635, 0.0035952829578173623, 0.001992376752999811, 0.0021748467951566318, 0.0012811562605398244, 0.0016324691702822628, 0.0016324691702822628, 0.0007748086679502573, 0.002687617566952455, 0.0014893811764403557, 0.0009007374673419615, 0.0022832390783598267, 0.002687617566952455, 0.0007748086679502573, 0.001204935592631292, 0.0021748467951566318, 0.001204935592631292, 0.0007748086679502573, 0.0009007374673419615, 0.0010364779698212217, 0.0007748086679502573, 0.0007098020796152977, 0.0021748467951566318, 0.0010364779698212217, 0.000904440814648145, 0.001992376752999811, 0.0007748086679502573, 0.0035952829578173623, 0.0012811562605398244, 0.0007748086679502573, 0.006911056861968096, 0.0010322339796835704, 0.0031244330898424293, 0.001992376752999811, 0.0007748086679502573, 0.006911056861968096, 0.0016324691702822628, 0.001992376752999811, 0.0010364779698212217, 0.0007098020796152977, 0.0007748086679502573, 0.0007748086679502573, 0.0007748086679502573, 0.0021748467951566318, 0.0007748086679502573, 0.0007748086679502573, 0.0021748467951566318, 0.0024621259636655635, 0.001204935592631292, 0.0012811562605398244, 0.002687617566952455, 0.0021748467951566318, 0.0007748086679502573, 0.0007748086679502573, 0.001992376752999811, 0.0007748086679502573, 0.0021748467951566318, 0.0035952829578173623, 0.0007748086679502573, 0.002687617566952455, 0.002687617566952455, 0.0007748086679502573, 0.0006761056223493568, 0.0012811562605398244, 0.0021748467951566318, 0.0035952829578173623, 0.0012811562605398244, 0.0012811562605398244, 0.000904440814648145, 0.0021748467951566318, 0.005166290955777485, 0.006911056861968096, 0.0007748086679502573, 0.0007748086679502573, 0.002687617566952455, 0.0012811562605398244, 0.0007098020796152977, 0.0010364779698212217, 0.0021748467951566318, 0.001992376752999811, 0.0006761056223493568, 0.0012811562605398244, 0.0012811562605398244, 0.0035952829578173623, ... ]\n",
      "Split on feature S. (128, 444)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (128 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (444 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007118013242425499, 0.0006520810635184079, 0.0021858655501184425, 0.0007787341981868901, 0.0007118013242425499, 0.0019979885265255467, 0.0009521917113017377, 0.0021858655501184425, 0.0007787341981868901, 0.0007118013242425499, 0.0007118013242425499, 0.003302914998577902, 0.0009922751888586342, 0.002469060843466345, 0.0011769727941046036, 0.001568014609919004, 0.002701234249960774, 0.003302914998577902, 0.0021858655501184425, 0.0019979885265255467, 0.0011769727941046036, 0.0017910056998897206, 0.0014997169820855068, 0.0007118013242425499, 0.002469060843466345, 0.001368264885957927, 0.0008274896094606551, 0.0020975663628523093, 0.002469060843466345, 0.0007118013242425499, 0.0013219523858018737, 0.002386056090626768, 0.0013219523858018737, 0.0008500538729211861, 0.000988212192598252, 0.0009521917113017377, 0.0008500538729211861, 0.0007787341981868901, 0.0019979885265255467, 0.0009521917113017377, 0.0009922751888586342, 0.0021858655501184425, 0.0007118013242425499, 0.003302914998577902, 0.0011769727941046036, 0.0008500538729211861, 0.0075822211269733495, 0.0009482928419098345, 0.0034278610430751874, 0.0021858655501184425, 0.0007118013242425499, 0.0075822211269733495, 0.0014997169820855068, 0.0021858655501184425, 0.0009521917113017377, 0.0007787341981868901, 0.0007118013242425499, 0.0007118013242425499, 0.0007118013242425499, 0.0019979885265255467, 0.0007118013242425499, 0.0007118013242425499, 0.002386056090626768, 0.002261906189079477, 0.0013219523858018737, 0.0011769727941046036, 0.002469060843466345, 0.0019979885265255467, 0.0007118013242425499, 0.0007118013242425499, 0.0021858655501184425, 0.0007118013242425499, 0.0019979885265255467, 0.0039444372900799725, 0.0007118013242425499, 0.002469060843466345, 0.0029486243716953645, 0.0007118013242425499, 0.0007417653242087336, 0.0011769727941046036, 0.002386056090626768, 0.003302914998577902, 0.0011769727941046036, 0.0014055751905437113, 0.0009922751888586342, 0.0019979885265255467, 0.00474616882316656, 0.0075822211269733495, 0.0007118013242425499, 0.0007118013242425499, 0.002469060843466345, 0.0014055751905437113, 0.0007787341981868901, 0.0009521917113017377, 0.002386056090626768, 0.0021858655501184425, 0.0007417653242087336, 0.0011769727941046036, 0.0011769727941046036, 0.003302914998577902, ... ]\n",
      "Split on feature Q. (552, 20)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (552 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (20 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007534103755331393, 0.0006179529988421083, 0.0020714635761282384, 0.0007379774693563214, 0.0007534103755331393, 0.0021147829244099236, 0.0010078530207214536, 0.0020714635761282384, 0.0007379774693563214, 0.0007534103755331393, 0.0007534103755331393, 0.0034959901656275412, 0.0009403423330886262, 0.002613392240130577, 0.0012457739043155746, 0.0016596744567139521, 0.0025598593468297392, 0.0034959901656275412, 0.0020714635761282384, 0.0021147829244099236, 0.0012457739043155746, 0.0018957007116723282, 0.001587384423411733, 0.0007534103755331393, 0.002613392240130577, 0.0012966538008723934, 0.0007841811613387876, 0.002220181681769019, 0.002613392240130577, 0.0007534103755331393, 0.0012527651650011253, 0.0025255353622658885, 0.0012527651650011253, 0.0008997446138533979, 0.0009364919824744858, 0.0010078530207214536, 0.0008997446138533979, 0.0007379774693563214, 0.0021147829244099236, 0.0010078530207214536, 0.0009403423330886262, 0.0020714635761282384, 0.0007534103755331393, 0.0034959901656275412, 0.0012457739043155746, 0.0008997446138533979, 0.007185389279694829, 0.0010037262390582777, 0.0032484565642083734, 0.0020714635761282384, 0.0007534103755331393, 0.007185389279694829, 0.001587384423411733, 0.0020714635761282384, 0.0010078530207214536, 0.0007379774693563214, 0.0007534103755331393, 0.0007534103755331393, 0.0007534103755331393, 0.0021147829244099236, 0.0007534103755331393, 0.0007534103755331393, 0.0025255353622658885, 0.0021435244647335628, 0.0012527651650011253, 0.0012457739043155746, 0.002613392240130577, 0.0021147829244099236, 0.0007534103755331393, 0.0007534103755331393, 0.0020714635761282384, 0.0007534103755331393, 0.0021147829244099236, 0.004175013277965498, 0.0007534103755331393, 0.002613392240130577, 0.003120989129303974, 0.0007534103755331393, 0.0007029434408946548, 0.0012457739043155746, 0.0025255353622658885, 0.0034959901656275412, 0.0012457739043155746, 0.001487739480218711, 0.0009403423330886262, 0.0021147829244099236, 0.0044977678717761154, 0.007185389279694829, 0.0007534103755331393, 0.0007534103755331393, 0.002613392240130577, 0.001487739480218711, 0.0007379774693563214, 0.0010078530207214536, 0.0025255353622658885, 0.0020714635761282384, 0.0007029434408946548, 0.0012457739043155746, 0.0012457739043155746, 0.0034959901656275412, ... ]\n",
      "Split on feature Age. (83, 489)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (83 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (489 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (572 data points).\n",
      "[0.0007226897858449104, 0.0006453875734293493, 0.002163428049301001, 0.000770740637371843, 0.0007226897858449104, 0.0020285518601582575, 0.0010525975545642673, 0.002163428049301001, 0.000770740637371843, 0.0007226897858449104, 0.0007226897858449104, 0.0036511977673948015, 0.0009820896697355867, 0.002506830194649533, 0.0011949770076950578, 0.0015920006103527788, 0.00267350658588358, 0.0036511977673948015, 0.002163428049301001, 0.0020285518601582575, 0.0011949770076950578, 0.0018184028065382789, 0.0015226582301805746, 0.0007226897858449104, 0.002506830194649533, 0.0012437822574507948, 0.0007522058813571701, 0.0023187486278957448, 0.002506830194649533, 0.0007226897858449104, 0.0013083827919467344, 0.0024225557138208022, 0.0013083827919467344, 0.0008630571908977149, 0.0008983061718270596, 0.0010525975545642673, 0.0008630571908977149, 0.000770740637371843, 0.0020285518601582575, 0.0010525975545642673, 0.0009820896697355867, 0.002163428049301001, 0.0007226897858449104, 0.0036511977673948015, 0.0011949770076950578, 0.0008630571908977149, 0.007504391046012851, 0.0009627989264663871, 0.0031159995335251134, 0.002163428049301001, 0.0007226897858449104, 0.007504391046012851, 0.0015226582301805746, 0.002163428049301001, 0.0010525975545642673, 0.000770740637371843, 0.0007226897858449104, 0.0007226897858449104, 0.0007226897858449104, 0.0020285518601582575, 0.0007226897858449104, 0.0007226897858449104, 0.0024225557138208022, 0.0022386881453330554, 0.0013083827919467344, 0.0011949770076950578, 0.002506830194649533, 0.0020285518601582575, 0.0007226897858449104, 0.0007226897858449104, 0.002163428049301001, 0.0007226897858449104, 0.0020285518601582575, 0.004360366716482158, 0.0007226897858449104, 0.002506830194649533, 0.0029937296309264488, 0.0007226897858449104, 0.0006742806593309218, 0.0011949770076950578, 0.0024225557138208022, 0.0036511977673948015, 0.0011949770076950578, 0.0014270763467936689, 0.0009820896697355867, 0.0020285518601582575, 0.004314369705532445, 0.007504391046012851, 0.0007226897858449104, 0.0007226897858449104, 0.002506830194649533, 0.0014270763467936689, 0.000770740637371843, 0.0010525975545642673, 0.0024225557138208022, 0.002163428049301001, 0.0006742806593309218, 0.0011949770076950578, 0.0011949770076950578, 0.0036511977673948015, ... ]\n",
      "Split on feature IsAlone. (261, 311)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (261 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (311 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, features, target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [Sex == 0]               [Sex == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: -1)                         (leaf, label: 1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [3 == 0]               [3 == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (leaf, label: 1)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(tree_stumps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6218971492563038, 0.3726164285952097, 0.1434322630168566, 0.12116534914748711, 0.14548377922363728, 0.06813340444625805, 0.08875044694752335, 0.05528385856192642, 0.04253431318677091, 0.04001943453649553]\n"
     ]
    }
   ],
   "source": [
    "#Quanto è importante ogni tree_stump nel momento in cui si fanno predizioni \n",
    "print stump_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    #creo un array di scores\n",
    "    scores = graphlab.SArray([0.]*len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x))\n",
    "        scores += stump_weights[i] * predictions\n",
    "        \n",
    "    return scores.apply(lambda score : +1 if score > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10-component ensemble = 0.802816901408\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_adaboost(stump_weights, tree_stumps, test_data)\n",
    "accuracy = graphlab.evaluation.accuracy(test_data[target], predictions)\n",
    "print 'Accuracy of 10-component ensemble = %s' % accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.223776223776\n",
      "Iteration 2, training error = 0.223776223776\n",
      "Iteration 3, training error = 0.223776223776\n",
      "Iteration 4, training error = 0.243006993007\n",
      "Iteration 5, training error = 0.218531468531\n",
      "Iteration 6, training error = 0.218531468531\n",
      "Iteration 7, training error = 0.222027972028\n",
      "Iteration 8, training error = 0.222027972028\n",
      "Iteration 9, training error = 0.222027972028\n",
      "Iteration 10, training error = 0.218531468531\n",
      "Iteration 11, training error = 0.218531468531\n",
      "Iteration 12, training error = 0.218531468531\n",
      "Iteration 13, training error = 0.218531468531\n",
      "Iteration 14, training error = 0.218531468531\n",
      "Iteration 15, training error = 0.218531468531\n",
      "Iteration 16, training error = 0.218531468531\n",
      "Iteration 17, training error = 0.218531468531\n",
      "Iteration 18, training error = 0.218531468531\n",
      "Iteration 19, training error = 0.218531468531\n",
      "Iteration 20, training error = 0.218531468531\n",
      "Iteration 21, training error = 0.218531468531\n",
      "Iteration 22, training error = 0.218531468531\n",
      "Iteration 23, training error = 0.218531468531\n",
      "Iteration 24, training error = 0.218531468531\n",
      "Iteration 25, training error = 0.218531468531\n",
      "Iteration 26, training error = 0.218531468531\n",
      "Iteration 27, training error = 0.218531468531\n",
      "Iteration 28, training error = 0.218531468531\n",
      "Iteration 29, training error = 0.218531468531\n",
      "Iteration 30, training error = 0.218531468531\n"
     ]
    }
   ],
   "source": [
    "#Calcola il training error alla fine di ogni iterazione\n",
    "error_all = []\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    error = 1.0 - graphlab.evaluation.accuracy(train_data[target], predictions)\n",
    "    error_all.append(error)\n",
    "    print \"Iteration %s, training error = %s\" % (n, error_all[n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.204225352113\n",
      "Iteration 2, training error = 0.204225352113\n",
      "Iteration 3, training error = 0.204225352113\n",
      "Iteration 4, training error = 0.225352112676\n",
      "Iteration 5, training error = 0.204225352113\n",
      "Iteration 6, training error = 0.204225352113\n",
      "Iteration 7, training error = 0.19014084507\n",
      "Iteration 8, training error = 0.19014084507\n",
      "Iteration 9, training error = 0.19014084507\n",
      "Iteration 10, training error = 0.197183098592\n",
      "Iteration 11, training error = 0.197183098592\n",
      "Iteration 12, training error = 0.197183098592\n",
      "Iteration 13, training error = 0.197183098592\n",
      "Iteration 14, training error = 0.197183098592\n",
      "Iteration 15, training error = 0.197183098592\n",
      "Iteration 16, training error = 0.197183098592\n",
      "Iteration 17, training error = 0.197183098592\n",
      "Iteration 18, training error = 0.197183098592\n",
      "Iteration 19, training error = 0.197183098592\n",
      "Iteration 20, training error = 0.197183098592\n",
      "Iteration 21, training error = 0.197183098592\n",
      "Iteration 22, training error = 0.197183098592\n",
      "Iteration 23, training error = 0.197183098592\n",
      "Iteration 24, training error = 0.197183098592\n",
      "Iteration 25, training error = 0.197183098592\n",
      "Iteration 26, training error = 0.197183098592\n",
      "Iteration 27, training error = 0.197183098592\n",
      "Iteration 28, training error = 0.197183098592\n",
      "Iteration 29, training error = 0.197183098592\n",
      "Iteration 30, training error = 0.197183098592\n"
     ]
    }
   ],
   "source": [
    "#Calcola il training error alla fine di ogni iterazione\n",
    "test_error_all = []\n",
    "for n in xrange(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    error = 1.0 - graphlab.evaluation.accuracy(test_data[target], predictions)\n",
    "    test_error_all.append(error)\n",
    "    print \"Iteration %s, training error = %s\" % (n, test_error_all[n-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
