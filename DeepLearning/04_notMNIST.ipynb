{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unità: notMNIST\n",
    "\n",
    "Elaborazioni base sul dataset notMNIST e semplice classificazione basata su Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessari\n",
    "\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# IPython: With this backend, the output of plotting commands is displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suppongo di aver scaricato notMNIST_large.tar.gz e notMNIST_small.tar.gz\n",
    "# decompressi in 2 directory notMNIST_large e notMNIST_small\n",
    "\n",
    "train_folder = \"DeepLearning/data/notMNIST_large/\"\n",
    "test_folder = \"DeepLearning/data/notMNIST_small/\"\n",
    "num_classes = 10 # notMNIST labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28  # dimensione immagine dataset: 28x28 pixel\n",
    "pixel_depth = 255.0 # scale di grigio\n",
    "\n",
    "def load_images(folder, min_num_images):\n",
    "    print (\"load from %s\" % folder)\n",
    "    image_files = os.listdir(folder)\n",
    "    # creo una matrice NUM_FILES x 28 x 28 di float per memorizzare il dataset\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        # posso avere errori nella lettura delle immagini\n",
    "        try:      \n",
    "            # leggo una immagine e la memorizzo come matrice\n",
    "            # opero anche la normalizzazione mean = 0 e standard deviation ~0.5\n",
    "            image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "            if image_data.shape != (image_size, image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            # accodo al dataset l'immagine\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images = num_images + 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "            \n",
    "    # cropping della matrice conteggiando le immagini effettivamente lette\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' % (num_images, min_num_images))\n",
    "    \n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recupero tutte le sottodirectory del parametro directory\n",
    "\n",
    "def list_subdirs(directory):\n",
    "    data_folders = [os.path.join(directory, d) for d in sorted(os.listdir(directory)) if os.path.isdir(os.path.join(directory, d))]\n",
    "    if len(data_folders) != num_classes:\n",
    "        raise Exception('Expected %d folders, one per class. Found %d instead.' % (num_classes, len(data_folders)))\n",
    "    # debug: print(data_folders)\n",
    "    return data_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBLEMA #1: FASE DI EXPLORATION \n",
    "\n",
    "Ho tanti dati, è opportuno dare un'occhiata veloce.\n",
    "\n",
    "Vediamo come sono fatti prendiamone uno per folder e visualizziamoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/A/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABzklEQVR4nG2STUiUURSGn3PunWZC\npzFiFmOO/VhQaLhIScdV0iKIoIWLCCLI0EW7ok1ta1EL+6GJlkXgIgsKwggiiCw0bDFSFGWWERWD\nIQVBP9/MafEx1fc1Z3fPy3ne93IOhCW0lY6kUOqVcNjsQQeursqrG9fsw2b8/4rSU95G0d611yF7\nzrxBGbGpNBJ3VB5dxkviul1EY6qjc6EfUbIvbWfcNsHQQgOCst0mM1GwCGPnEEA5a0PRTErzfD8O\nUFa//bwiMqoMPE6GHc8BO00iYnrzRK2h3P3WRUJVQ7jQOrsJBRHnPBvsCn/BnuJ9kk5rowftUGd3\n35aVzkPiV/ee/fw0aGjJr1q3Jp/j1GSp9BQEV8nc7u1Lta/P5VJB8KP8cc4daypMaxUQsnesYl8m\nzg/3tKQF8FywEZKqQGHebHp37W/O+yVstZnG8H3UbDyJiPcqImGkKduBB6URkk7UgqBqZmHiSxQw\nYOm4vV4cjS6QbHViGQJd3+3k8uK+2CZGbSMKt+xhM9IU0Ry7bC8Cw8fz+NjNKW3lq388IlDnnWPs\nK6Dei4H9I1aCivIkvRbxQYxY7RhYnHn+6T29cxK/4SrPWgcHE7OZey+w38GSigZs2e7gAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/B/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB8klEQVR4nFWSTUiUURSGn3vOp5l/\npTFUNCYttIwyJFq0KSiIapOhgUFuApGg2kbYrlXSpk1QixZBm8SihUQJRWFIYGmQY2BEM01KjEWF\nDoTe77T45uebs7rwnPOen/cCiFB74VXmx/z4KcRREeJc39vXV/cn2i/P3wtcBVV2vrDFHgRH/cyY\nw8XZ+b8//9ks6qSKRO4SEqscWu1ty9k0AgRcT8dVBxb2wDObq8KBMpSLw9RRahiwhR2R3NTduOwD\nVGgPrZsAR9JOoOU9bqs3sm/oBIS+9BRWrnS1GwgYtqcBTpgYJYhdwPxGNT5yeCsatrWPxAujDDp/\n2Vmq6V9tQCpu5ABSdp+AJ49w4FRVBRAwEGbpYI0tXQeaG2rMe+9D0VL7md5EyzcGhx/m66pXctnM\nh3effMEhCU+OLR+bVE9TsrEhkWhubt2evzZenGiXtx4CkdIc9VfyfUWYmLOLBOBEoxBufI1Sjd8Z\nkoRgoY9CmG4tQFnNRrAUxsH3hSbKd1qqY59AfPLcrcI7YMDSjWUY4CZGi+YZmXBbbRGprjVNLp8p\nX7fjj3VFqSqO0+k76yjvVZe1blQCxdH1fLEHdSVZt7JEEsI1X3V8/GVq96iGFrP28742Nm/ae+jI\n+seDX0R9haU3Lb+0lE6N9DfiNBr7Pz2Gqxdz3P8PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/C/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABOklEQVR4nH3SzyvDcRzH8ef7/fnG\noiWrTaQpLvMjlCIHOSAlJxdbDv4Cf4HyF1A4iiMnJwd9SRaRduC8w2pZTW3SGnHy3ddhB7LvZ6/r\no/fr8+7dR6hHxUPj4XKJxqgwefzmvayhjUb4xH8+SsUC5gyJQmkFAQmw4cp5CDGm0YRo/hScRgGB\ndIaAReqlG5U+TKApva+rOIGG4eDCMgckimOWB4HtM1sphHJz9tZkxgm4Sz26mP12fBuOXmMztD/f\nBMNlG4G+dzbB4oB1WfRuyY5M5OKB1xNVYNfF/FcxCtoCrQ97yN9vIEaByMJyTMRvd7+SFRGt+SAi\nng8d81PObboKgrNf3Ir8rtW1fni5M+sgCCi1mc3Bx/unYtXpHhpJRLOuW0XUQwAR3x9PTfe0hT4r\nhdzVzQcYPOAHCaBPo3FwOCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/D/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABwklEQVR4nG2Ru2uTURiHn/d9P2OM\nNhGaaqliS5GmijaimHohWxAdvCDo4tQ/QJycpFtctIOriog6KkgHhVrUQQwoXhbb0gopttZLsIOt\nF4rmfA5fPpt86W868Jzfj+dwJL3tcC6+Kr5afv38+vrJmz8YVWqRC8WJyy9mfieSqfTuXKeUbo6J\nOj/E+V40POveq1PDOdTCKi1nuxARVTOEdefKt9N4ATQOuWzYFfWE1hvlY5gE8OjfrcvDiCn5uSIq\ngNLtn8SgDrN54hYiIMTnLzVAMOKlO7W10WcRiNEyPYiBR7HiIVHav9APGMd/7KgzCuIx9BwQNiye\nDh/2P0rmyxHF18qHLH4EOpt8dUpBGNmDoymlvAKM9jU1gffdCj5j3zNRXeCTKjidndrfpAttiwoI\nL1dqdnxUwPGwfQWjwtNgbbzS4RqrUk1kHinge0vlnZFdY2B+OLhG52CjkZKaKQCoIJzpqq+aMHKl\n9lVmbNyyDNVD7z4GAdueBDFVARE1E6Fn/H4MAeHAtYu5WJ0nvdcXhlAFQfzkiUJs9u303LfqmkSq\n5+C+bOn8O3M+CKiDTbv62lrXr21PLdnnB/cmsSrAP+XFcgUNPAuGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/E/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpUlEQVR4nHWQy2pTYRSFv7333xpi\nY2mSNjUKIVXEQYsIgg68DhRLcS4ihL6AD+CL+AK+ghMvaBGEDtRgvddr1WgwjakJTYk553eQk6JN\nzhpt9sdea7MEMQIPtr8wd2gql5VWsPmzWVkuV0EsAHdktpjsdL5XftSarTCRTOcni6mXtxrC2LmF\nUytLj9Z+8b+m2k2uV7wvIaBmpiKCiKiZALxbKrXHcSo7DhFgOpurnUV3IgC0ul59dTwOMsLrY0MR\nqA94UBztDkT2g/PrByJfEVU1c27EOdPeV+WrmJoNBAtYcGPisusCsjs1lprIZjLZRLv+qfzGgfDk\nGqcv7U14UVVajY2N1a3xPXMHbwtoePju/PPZpG41W7/bfsD68yIWzWp9Kb2XHp5HVFVFfBj0FQJg\nLH6LaQg8j93RYQ324LP6mVho3D9JMLxAlBNfEsTWK3cuDvFVAG/+5oW4S2DXfPJfKqoq2wvxoiFe\nepvQR3ERm5xZlu1eJZ1Jj9bfS8S4N1P6Wtt0uel8YV9eGtXVpx87fVsrLFxJSyeUP621FytvP3QB\n/gIbOImgV3bDCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/F/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABc0lEQVR4nH2Ry05TURSGv7X3tnro\nwQQvTArVSMJEMA6MI0fOfBkNz2FkxhAegYQJM0xIjJIIA0IHpGBIT6QCSUmgF05O94VBoVDT03+4\nvv3/a+215Nvn40at/q9+XD/rpJYBSa28+WNyIo7jWF90uml6lQWyqzRrN6oVOddvj5QHVRh//mSi\nGBWj6JFtXl7WklabrYtpHmhhmNTZ42d4FxARpbTWxhhjjNZKQFV4CUAIwXvnnLXWWuucD6C2eTc0\nEoCp9gY6l+7+LTB8HhTfS7P/QVFaSQ9uMou5K2stwTsfAAz7vF+1ogBwAVCl6dLYyc+WBIHDZOnF\nYs/5sDwz93qslexVjrqAwO6bxtPfyyeFV/MzhdDa+bVXDbdd+LTOytrHuah5WjuoHpwDKPE3/EsI\nC/2JUPreng1bzXHQ4WaHfvCfO3/o4nq6TevH2ISB5wNOOqNgF5cPs1FwpNOO7pkS8iDEOddWsM2H\n3GDh62l5uPUaOz6c5qTQyKQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/G/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nHWRT0jTcRjGP8/3+52o\nO8ymS4siKGxIUBBWh6goOhQlHbKgiMA6diwIOgZKdeoPCUG3OkRCLIoOIw/B8lKMEGIElUhBLUok\nUnPN39thZrrN5/h+eN4/zwsAzrFjsFCOCtc6cSyVY8XNWYuePS7ZZC+qYm0jNjF0CtJXPtvpJV7R\nPGyPusA5aDnUU2W8bf3CB+R81UDPQbtKmC/LL23amM8iUU+Ok6XNVLdbcL4dJNRncPhruubwBd1/\nvjxb86l3WRi2r8z9Gy4hGRZh83B/fgIDaaEEOEUGhL25kgzMfMeGVFsqMV0c+/CxDD4yQucQvixr\nP7uv48/U1PRMcmtqppjPPJmUi7ALxIB417rWJgHEV6WP3Br/MZBE2KVFEciHyuZNx95/3w3fblQu\nkVQJWM75IPz13zt58DJGberyIvOa47a+DoQGLhoto3fr/UROT9/AmdldtV/xgb65PYjM2GpiWmwK\nDp2fOAqi+cWXTch7J8n54BENPblX3ThwJLNzlxP/t3Jb+gvj5wIegRT1DdhI9l3xZ2Ni7cbube2F\nO/dmHRECpCh+4ERXvDWmYL8Kww9HK7nzF/CwhrMCHwvDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/H/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABnklEQVR4nHWSMU+TURSGn3PubXHB\nqoklSjWSaKxhK4QoOBAmNQyKTgzO+gMcXfAPOBl+gInpoImJJspi4uBAjFUEgQFJMLpIIU1NY4V7\nr8NtP/t96lmf95x7z3teAGtIlTJ5GeGfpUw/GUzg7TnbIxQKz4dQADXMPDi4r6Gn8Vpt0/qO8Fk4\nGYVdWL1B/IUGO/H+K38agbM/El3x0KqzKaiHE1hgM/Pdz+UE9vElNVVYriSwFbYznbXTOInwe6ud\nQoGV/Bk6sNF0KehZc8Nd6OvF9FTD0njnTaFeyrr86mICd0s9KxqAt8UjTiJsHIsriDF4l1NHbW8E\njdLdo5iclRCcs5VbFzz218Z5AKyn2U9bAvkTEyOnvlXfQGDh6r0AyJXZ6XbV7+ULA2Hr3YstAPWj\njypNCdhPi+cqxz/+3FlfrXtQPAQ+tMZfqgOhsD0W72lsZyXL47sYUHKNlevkjYq4/dB18OlUPIbh\nzmJvEgCltD6MAkJxqZyhhvmHMSrKpXLGQGFgYzJSkb8SbLi5diAxOFvK/fn/pR4kzL3+DSTqe2vV\n5VkWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/I/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABcklEQVR4nHXTzUpbURDA8f+cc2vb\nhaQiVEkDJogf1Vq6ULBkZx+g+AY+QCn1RcQHcCnSfTcuLHRXN4mUlNuWVg0mNKDERgVDlMx0cZOb\nRLyzOoffmTkzHI58mJoYTaVum+dn5f3ib4NAlU7I+mH4rxU8TqUz2Vzm4u/e1zNEOiz0x/xS/tnJ\nxy+4SMWjAGLmUODJyqrbKDgdSHq0NYtz3gP57TVcHwkj12/xgHiPe/+6XwXK6wTRxkEOiRYA5jiZ\n6p5U4RjrIY5vM3S7sM4QvdKlHL0WbQCN8GHqztQxKiETSQjn9UQ0z69ZuB8RSpOJqBxkEtH4MRS0\n5X6EyvVYYqZv1cdJzKSUTUQjfJpUFuPP0IBI/ISKUb307RjaSgdFAbmpDDdi8NMPqhHa4tGFwU8N\nVBV4sTBHWGgI4PTNVi6+a2F5aboe7habUVmjdvNpp3h6O/b85asZLX/eDAFnJgBio+/y6eF266p2\nsPe9QfdP/AdEc4FKhvHfAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning/data/notMNIST_large/J/VmFkaW0ncyBXcml0aW5nLnR0Zg==.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZklEQVR4nH2Suy+DYRTGn3Per6qq\nJY1qDJJ2QMIgdUlYGBiIEAmzLh0lRhGXxV9gsHQhJoPEIiYDkYiFImniEgwk9CLtp4jevs/QrxXV\nt2d6T37vc54nJwcoraXkFjj/JIB022Q7RSPhl0gynR3bW1klPQ8VQMdX0DXYZ1c5p36kO5Pu2eB9\nPGUojV/VWpXF5mnp8QVPlMvd14IaIIWLnofr+G0KnIiIuQrup2EoVIoLIWYuaiCBYGxuQJFAgvXK\nL6UC/S/e/6GKtgs39gq2BzsQEspwRucgpIMnvrsr2AYuJQggmO/mpZQx9OCWBYbIBcIVpJ5tWSJo\n4rFOCjnn1hlc3taE6Xj5FRIL9N52Ad6OEkBCIcJ42Ae0xkJg40ZYKMYxDezfj4FxpE39Hc0NI2un\n14tWMJT6eNvo8/unMJtNVqfL1djU7Hg7Xz7+BmugWv9Eo8NCmWwmm1LVROL2LBTTAaFrwA9xEWNi\nyAApNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_subfolders = list_subdirs(train_folder)\n",
    "\n",
    "for folder in train_subfolders:\n",
    "    fn_images = os.listdir(folder)\n",
    "    for file in fn_images[:1]:\n",
    "        path = folder + os.sep + file\n",
    "        print (path)\n",
    "        display(Image(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carica le immagini presenti nel data_folders e serializza la matrice corrispondente su un file con estensione .pickle\n",
    "\n",
    "def serialize_folder_images(data_folders, min_num_images_per_class):\n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "\n",
    "        set_filename = folder + '.pickle'\n",
    "        if os.path.isfile(set_filename):\n",
    "            print ('pickle file %s exists, so I skip it', set_filename)\n",
    "            continue\n",
    "        dataset_names.append(set_filename)\n",
    "        dataset = load_images(folder, min_num_images_per_class)\n",
    "        try:\n",
    "            with open(set_filename, 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "    return dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png : cannot identify image file 'DeepLearning/data/notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/A/.DS_Store : cannot identify image file 'DeepLearning/data/notMNIST_large/A/.DS_Store' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png : cannot identify image file 'DeepLearning/data/notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png : cannot identify image file 'DeepLearning/data/notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52909, 28, 28)\nMean: -0.12825\nStandard deviation: 0.443121"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nload from DeepLearning/data/notMNIST_large/B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png : cannot identify image file 'DeepLearning/data/notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52911, 28, 28)\nMean: -0.00756303\nStandard deviation: 0.454491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: -0.142258\nStandard deviation: 0.439806"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nload from DeepLearning/data/notMNIST_large/D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png : cannot identify image file 'DeepLearning/data/notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52911, 28, 28)\nMean: -0.0573677\nStandard deviation: 0.455647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: -0.069899\nStandard deviation: 0.452941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: -0.125583\nStandard deviation: 0.447089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: -0.0945816\nStandard deviation: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44624\nload from DeepLearning/data/notMNIST_large/H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: -0.0685221\nStandard deviation: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454232\nload from DeepLearning/data/notMNIST_large/I\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52912, 28, 28)\nMean: 0.0307863\nStandard deviation: 0.468898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from DeepLearning/data/notMNIST_large/J\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (52911, 28, 28)\nMean: -0.153358\nStandard deviation: 0.443656"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nload from DeepLearning/data/notMNIST_small/A\nCould not read: DeepLearning/data/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png : cannot identify image file 'DeepLearning/data/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: -0.132626\nStandard deviation: 0.445128\nload from DeepLearning/data/notMNIST_small/B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1873, 28, 28)\nMean: 0.00535608\nStandard deviation: 0.457115\nload from DeepLearning/data/notMNIST_small/C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1873, 28, 28)\nMean: -0.141521\nStandard deviation: 0.44269\nload from DeepLearning/data/notMNIST_small/D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1873, 28, 28)\nMean: -0.0492167\nStandard deviation: 0.459759\nload from DeepLearning/data/notMNIST_small/E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1873, 28, 28)\nMean: -0.0599148\nStandard deviation: 0.45735\nload from DeepLearning/data/notMNIST_small/F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read: DeepLearning/data/notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png : cannot identify image file 'DeepLearning/data/notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png' - it's ok, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: -0.118185\nStandard deviation: 0.452279\nload from DeepLearning/data/notMNIST_small/G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: -0.0925503\nStandard deviation: 0.449006\nload from DeepLearning/data/notMNIST_small/H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: -0.0586892\nStandard deviation: 0.458759\nload from DeepLearning/data/notMNIST_small/I\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: 0.0526451\nStandard deviation: 0.471894\nload from DeepLearning/data/notMNIST_small/J\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset tensor: (1872, 28, 28)\nMean: -0.151689\nStandard deviation: 0.448014\ndone!\n"
     ]
    }
   ],
   "source": [
    "train_subfolders = list_subdirs(train_folder)\n",
    "test_subfolders = list_subdirs(test_folder)\n",
    "train_datasets = serialize_folder_images(train_subfolders, 45000)\n",
    "test_datasets = serialize_folder_images(test_subfolders, 1800)\n",
    "print (\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBLEMA #2: VISUALIZZAZIONE\n",
    "\n",
    "Ora prova a visualizzare i dati a partire dagli oggetti ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEW5JREFUeJzt3XuMXOV5x/Hfs1eDTcDmsjjGBUwgjYFgkg3hpioVlwJC\nAtTKClUjV6EYVAq4DRKIRgVVqgSh3NqAGwNWTEq4SISCVEMLbisn4roQczXGxJjaZrFBpo7BsJ7d\nefrHHkcL7HnOMrcz6/f7kaydnWfOnGfH+9szM++c9zV3F4D0dJTdAIByEH4gUYQfSBThBxJF+IFE\nEX4gUYQfSBThBxJF+IFEdbVyZz3W61M0tZW7BGpjFpZ9rz3C+vD+1Xj7HZ25tZ7Bj8Jto94+8Y+0\n0z+Jm8/UFX4zO0PSrZI6Jd3p7tdFt5+iqfq2nVLPLoGWsN7esL7zhKPD+vt/GQe48sL03Nrv/f2T\n4bbW3ZNbe7ryWLjtWDU/7TezTkm3STpT0lxJ55vZ3FrvD0Br1fOa/zhJb7r7OnffKek+Sec0pi0A\nzVZP+GdJ2jDm+43ZdZ9iZgvNbMDMBioaqmN3ABqp6e/2u/sSd+939/5uxa+jALROPeHfJGn2mO8P\nyq4DMAnUE/7nJB1uZoeaWY+k70p6pDFtAWi2mof63H3YzP5K0n9odKhvqbu/2rDOsHuIxssLZpHq\n3GfvsL7hL44M69UTtuXWjp/1drjtt/deF9b/bK9fhvU9O/KH4yTpxHsvDushjz5DMPGZueoa53f3\n5ZKW13MfAMrBx3uBRBF+IFGEH0gU4QcSRfiBRBF+IFEtPZ8f6bGu7tyaV3aG225YGI/jv7zo9pp6\naox4HP/sN84M63vd/3R+sSP/XH9J8uHhoBhu+undTPymAHYnhB9IFOEHEkX4gUQRfiBRhB9IFEN9\naFs92+JxqyGvhPUd1fz6nh35Q5CSVPGRsL6HxUN9G/7t0LB+oAZza9ZZMNRXjXubKI78QKIIP5Ao\nwg8kivADiSL8QKIIP5Aowg8kinF+1KdgKetomulotVlJ+sb3XwrrvRaP1Xd05B/bui0eSy/SafFx\nc+q78RLdoXBq7sbhyA8kivADiSL8QKIIP5Aowg8kivADiSL8QKLqGuc3s/WStksakTTs7v2NaAqT\nRzQ1txRPz73u+hPCbR+bvTis76jGU38XLZPdTNaaofq6NOJDPn/o7u834H4AtBBP+4FE1Rt+l/SE\nmT1vZgsb0RCA1qj3af/J7r7JzA6Q9LiZve7uK8feIPujsFCSpmjPOncHoFHqOvK7+6bs6xZJD0k6\nbpzbLHH3fnfv71ZvPbsD0EA1h9/MpprZXrsuSzpd0iuNagxAc9XztL9P0kM2ekpnl6Sfu/tjDekK\nQNPVHH53XyfpmAb2gjZkXfGvSNEy25VTv5lbe/ZPbwy3HfEpYb3McfzdAUN9QKIIP5Aowg8kivAD\niSL8QKIIP5Aopu5OXcHU216Nl8nu/NKXwvqpt/xPbm16Z/xx7xUfx9NrP7j1W2H99llP59aKluBO\nAUd+IFGEH0gU4QcSRfiBRBF+IFGEH0gU4QcSxTh/4uqZeluS1tx2WFhfPmNlWI9cceNFYX3b7xeM\n1f9J7eP8nUVLj+8GOPIDiSL8QKIIP5Aowg8kivADiSL8QKIIP5Aoxvl3c/VOvb31+/Ey2r85JV5G\nOzJ/3Slh/YDbnwzr238+r+Z9N5tPgsPqJGgRQDMQfiBRhB9IFOEHEkX4gUQRfiBRhB9IVOE4v5kt\nlXS2pC3uflR23QxJ90s6RNJ6SfPd/YPmtYlQR/789j5ScN76EfH5+Lf88LawPhJP669VO4dzax8u\n3Dfe2LbG5XjrUnk7N5eZyJH/p5LO+Mx1V0la4e6HS1qRfQ9gEikMv7uvlPTZP8HnSFqWXV4m6dwG\n9wWgyWp9zd/n7oPZ5Xcl9TWoHwAtUvcbfu7uknJf+ZnZQjMbMLOBiobq3R2ABqk1/JvNbKYkZV+3\n5N3Q3Ze4e7+793ert8bdAWi0WsP/iKQF2eUFkh5uTDsAWqUw/GZ2r6SnJH3VzDaa2QWSrpN0mpmt\nlXRq9j2ASaRwnN/dz88pxSdjo3EK5pC3jvy6D8cD8V13fBTWT5pS39tCF15/eW5t/9eequu+q9U2\nHkxv49Z24RN+QKIIP5Aowg8kivADiSL8QKIIP5Aopu6eBOpZRnv9P8RTb685vPaptyXpmGfzRoJH\nHfgv+cN5ndOnh9tWP4yHIa2j4HziEjF1N4C2RfiBRBF+IFGEH0gU4QcSRfiBRBF+IFGM87eBepfR\nrpzen1t7dsFN4bYjHs+udM17x4T1A89dHdbDfX9Q32zvIzva99fXg9Os2wVHfiBRhB9IFOEHEkX4\ngUQRfiBRhB9IFOEHEtW+A6W7k4Kpt70an5feue+MsH7eLY/m1vbu2CPctuLxEt5D1fhXZP39R4f1\nrq74/iPVanxsuvLI/J+7SLflL2suSVVVa75vifP5AbQxwg8kivADiSL8QKIIP5Aowg8kivADiSoc\n5zezpZLOlrTF3Y/KrrtW0oWS3studrW7L29Wk5NdPfPuS9K6xbPC+sX7/Fdubcgr4ba9Fvd2w4G/\nrqverorG+Ye8vnH+go9HtIWJHPl/KumMca6/2d3nZf8IPjDJFIbf3VdK2tqCXgC0UD2v+S81s5fM\nbKmZxesuAWg7tYZ/saQ5kuZJGpR0Y94NzWyhmQ2Y2UBFQzXuDkCj1RR+d9/s7iPuXpV0h6Tjgtsu\ncfd+d+/vVjxZJIDWqSn8ZjZzzLfnSXqlMe0AaJWJDPXdK+k7kvYzs42SrpH0HTObJ8klrZd0URN7\nBNAEheF39/EWYL+rCb1MWtbdE9aLxvE3X3piWH/95NvDejSW31Hw5G7j8IdhvRJPNaCKypufvq8z\n/tmK5jJopt1lnB/AbojwA4ki/ECiCD+QKMIPJIrwA4maBAMSbaIj/xTQoqE8O/bIsP7AFTeE9YpP\nCevbqvn7n3/xonDbqS++E9ZVMJymkTpOfe2KT6vVcDzt97qb4ynNV5/0s9zajuAxk6TOgunWi1S7\nWaIbQJsi/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMb5dykY17WO/Lr1xOPwX71zTVg/ontqWC9y0j1X\n5Nbm/PtT4bbDde25XEMf95XdQq6RSTBpFUd+IFGEH0gU4QcSRfiBRBF+IFGEH0gU4QcSxTh/pp5l\ntNf8ZF647aMz76ypp10ue+dbYf2wHz6XX+yK/4u9WjA3d51LVUesp2DK853xOfcdnQW9l2iknlnD\nrTXHZI78QKIIP5Aowg8kivADiSL8QKIIP5Aowg8kqnCc38xmS7pbUp8kl7TE3W81sxmS7pd0iKT1\nkua7+wfNa7U+9S6j/f5FJ+TW3jpzcbhttIS2JG0vmEP+9cvmhnUbfjG/GKw3IEmqxnPjN1XhZwzi\nekG5LiNFd14wLX9lWvt+BmGXiRz5hyX9wN3nSjpe0iVmNlfSVZJWuPvhklZk3wOYJArD7+6D7v5C\ndnm7pNWSZkk6R9Ky7GbLJJ3brCYBNN4Xes1vZodIOlbSM5L63H0wK72r0ZcFACaJCYffzKZJelDS\nInf/7diau7tG3w8Yb7uFZjZgZgMVDdXVLIDGmVD4zaxbo8G/x91/kV292cxmZvWZkraMt627L3H3\nfnfv79YkmNUQSERh+M3MJN0labW73zSm9IikBdnlBZIebnx7AJplIqf0niTpe5JeNrNV2XVXS7pO\n0gNmdoGktyXNb06LE1QwpFU0lKfjvx6WH7g6fxntisfnb/ZafLrwUfdeFtbnPBlPvx0NYxb+3GiK\n4X3af1L0wvC7+6+UP6p5SmPbAdAqfMIPSBThBxJF+IFEEX4gUYQfSBThBxI1uabujsbyC6aY7txv\n37B++l0rw/ph3dNyayMF+75p65yw/pW/+3VYrxZ9hmE4PmUYrTftgI/KbqEQR34gUYQfSBThBxJF\n+IFEEX4gUYQfSBThBxLVXuP8BePZ1pE/X7IPx1MlD903Nawvmr4+rG+rfpxb27sjPp//7p+cEdb7\nPnkyrFvRMtsFP/ukVfD70NHRvJ+70wrm5i5w7IEbw/rm4P59pGA69ai3L/CQcOQHEkX4gUQRfiBR\nhB9IFOEHEkX4gUQRfiBRrR3nt3jM2ofjuc6j0+bXLvtGuO26uUvD+o6CZbKjsfwPRnaE23750cGw\nPlI0pmyT+G90OCYdz4NQtHz4Nw/+3xoaGlU0jt+lgqXNC1wx8z/D+lV7/1FubeT/toXbhp/7YJwf\nQBHCDySK8AOJIvxAogg/kCjCDySK8AOJKhznN7PZku6W1KfRUcQl7n6rmV0r6UJJ72U3vdrdl4d3\n5vFYfsfU+Jz71//5a7m1t067M9y2aBy/1+KHouL5Y87TOnrDbTecNzOsf/mGt8K6V+Le25rnDzwX\nfa5jyyUnhvUHD74prFe8O7fWa/m1iYh+HyTp6z1Twvrr/3RYbu1rV74Tbjs8+G5+8QuM80/kQz7D\nkn7g7i+Y2V6Snjezx7Paze7+jxPfHYB2URh+dx+UNJhd3m5mqyXNanZjAJrrC73mN7NDJB0r6Zns\nqkvN7CUzW2pm03O2WWhmA2Y2UNFQXc0CaJwJh9/Mpkl6UNIid/+tpMWS5kiap9FnBjeOt527L3H3\nfnfv71b82hhA60wo/GbWrdHg3+Puv5Akd9/s7iPuXpV0h6TjmtcmgEYrDL+ZmaS7JK1295vGXD/2\nLezzJL3S+PYANIt5MBQjSWZ2sqRfSnpZ0q5zMK+WdL5Gn/K7pPWSLsreHMw1bcZsP/q0y3Prf3zN\n47k1SfqbGetya0VDL91W3yma0TLcnQWn3Bb19tfvxENay1cfGdaPuPDV3JoP1fk+S51TWHf1HZBb\ne+vH+4fbvnbiv4b1oqXRI0X/Z2VaVfB/dsEr38utrVm0VDvWDk7oP20i7/b/StJ4dxaP6QNoa+37\n5w9AUxF+IFGEH0gU4QcSRfiBRBF+IFEtnbr7oIO26EfXL86tnzQl/lsUnZa7Z0dPzX1NRDPHhX88\n65mwPue1eJzfdwan/BYsc100PbZ1xae+Fp1u/MaiObm1tSfm/y5I0pBXwnq9p+WWKfpd/kp3/Nmb\n7S/vm1urfjzxSHPkBxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUYXn8zd0Z2bvSXp7zFX7SXq/ZQ18\nMe3aW7v2JdFbrRrZ28HuHk+UkGlp+D+3c7MBd+8vrYFAu/bWrn1J9FarsnrjaT+QKMIPJKrs8C8p\nef+Rdu2tXfuS6K1WpfRW6mt+AOUp+8gPoCSlhN/MzjCzNWb2ppldVUYPecxsvZm9bGarzGyg5F6W\nmtkWM3tlzHUzzOxxM1ubfR13mbSServWzDZlj90qMzurpN5mm9l/m9lrZvaqmV2eXV/qYxf0Vcrj\n1vKn/WbWKekNSadJ2ijpOUnnu/trLW0kh5mtl9Tv7qWPCZvZH0j6UNLd7n5Udt2PJG119+uyP5zT\n3f3KNuntWkkflr1yc7agzMyxK0tLOlfSn6vExy7oa75KeNzKOPIfJ+lNd1/n7jsl3SfpnBL6aHvu\nvlLS1s9cfY6kZdnlZRr95Wm5nN7agrsPuvsL2eXtknatLF3qYxf0VYoywj9L0oYx329Uey357ZKe\nMLPnzWxh2c2Mo2/MykjvSuors5lxFK7c3EqfWVm6bR67Wla8bjTe8Pu8k919nqQzJV2SPb1tSz76\nmq2dhmsmtHJzq4yzsvTvlPnY1bridaOVEf5NkmaP+f6g7Lq24O6bsq9bJD2k9lt9ePOuRVKzr1tK\n7ud32mnl5vFWllYbPHbttOJ1GeF/TtLhZnaomfVI+q6kR0ro43PMbGr2RozMbKqk09V+qw8/ImlB\ndnmBpIdL7OVT2mXl5ryVpVXyY9d2K167e8v/STpLo+/4/0bS35bRQ05fcyS9mP17tezeJN2r0aeB\nFY2+N3KBpH0lrZC0VtITkma0UW8/0+hqzi9pNGgzS+rtZI0+pX9J0qrs31llP3ZBX6U8bnzCD0gU\nb/gBiSL8QKIIP5Aowg8kivADiSL8QKIIP5Aowg8k6v8BmANeQKi8ANcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114239190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prendo il fn del pickle relativo al label A\n",
    "\n",
    "pickle_file = train_datasets[0]  \n",
    "\n",
    "with open(pickle_file, 'rb') as f:        \n",
    "    # unpickle\n",
    "    letter_set = pickle.load(f)  \n",
    "    # prendo in indice a caso\n",
    "    sample_idx = np.random.randint(len(letter_set))    \n",
    "    # estraggo la matrice relativa all'indice\n",
    "    sample_image = letter_set[sample_idx, :, :]  \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(sample_image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBLEMA #3: BILANCIAMENTO \n",
    "\n",
    "Nella classificazione multiclass è opportuno avere un dataset bilanciato verifica che il numero di file per label sia più o meno lo stesso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/A.pickle  contains  52909  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/B.pickle  contains  52911  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/C.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/D.pickle  contains  52911  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/E.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/F.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/G.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/H.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/I.pickle  contains  52912  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle file  DeepLearning/data/notMNIST_large/J.pickle  contains  52911  samples\n"
     ]
    }
   ],
   "source": [
    "for pickle_file in train_datasets:\n",
    "    with open(pickle_file, 'rb') as f:        \n",
    "        # unpickle\n",
    "        letter_set = pickle.load(f)  \n",
    "        print(\"pickle file \", pickle_file, \" contains \", len(letter_set), \" samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crea una matrice di double per il dataset, e un array di int per i label, di dimensioni nb_rows x nb_rows e nb_rows rispettivamente\n",
    "\n",
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "        labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "    else:\n",
    "        dataset, labels = None, None\n",
    "    return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fa il merge dei pickle files \n",
    "# il merge ottenuto lo suddivide in due datasets: uno per il training e uno per la validazione\n",
    "# il primo ha dimensione train_size e il secondo valid_size\n",
    "\n",
    "def merge_pickles(pickle_files, train_size, valid_size=0):\n",
    "\tnum_classes = len(pickle_files)\n",
    "\tvalid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "\ttrain_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "    \n",
    "    # numero di istanze da considerare (fisso) per label \n",
    "\tvalid_size_per_class = valid_size // num_classes\n",
    "\ttrain_size_per_class = train_size // num_classes\n",
    "\t\t\n",
    "\tstart_v, start_t = 0, 0\n",
    "\tend_v, end_t = valid_size_per_class, train_size_per_class\n",
    "\tend_l = valid_size_per_class+train_size_per_class\n",
    "    \n",
    "    # itera sui pickle files insieme a un contatore (label)\n",
    "\tfor label, pickle_file in enumerate(pickle_files):\t\t\t \n",
    "\t\ttry:\n",
    "\t\t\twith open(pickle_file, 'rb') as f:\n",
    "\t\t\t\tletter_set = pickle.load(f)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# faccio uno shuffle del dataset, perche'? \n",
    "\t\t\t\tnp.random.shuffle(letter_set)\n",
    "\t\t\t\tif valid_dataset is not None:\n",
    "                    \n",
    "                    # di tutto il pickle prendo solo valid_size_per_class istanze\n",
    "\t\t\t\t\tvalid_letter = letter_set[:valid_size_per_class, :, :]\n",
    "\t\t\t\t\tvalid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "\t\t\t\t\tvalid_labels[start_v:end_v] = label\n",
    "\t\t\t\t\tstart_v += valid_size_per_class\n",
    "\t\t\t\t\tend_v += valid_size_per_class\n",
    "\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\ttrain_letters = letter_set[valid_size_per_class:end_l, :, :]\n",
    "\t\t\t\ttrain_dataset[start_t:end_t, :, :] = train_letters\n",
    "\t\t\t\ttrain_labels[start_t:end_t] = label\n",
    "\t\t\t\tstart_t += train_size_per_class\n",
    "\t\t\t\tend_t += train_size_per_class\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint('Unable to process data from', pickle_file, ':', e)\n",
    "\t\t\traise\n",
    "\t\t\n",
    "\treturn valid_dataset, valid_labels, train_dataset, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le dimensioni dei dataset per il training, la validazione e il test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\nValidation: (10000, 28, 28) (10000,)\nTesting: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_pickles(\n",
    "                                                            train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_pickles(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dato un dataset e i corrispondenti labels, fa un nuovo shuffle (fondamentale per l'apprendimento)\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    \n",
    "    # restituisce un array contenente le permutazioni del numero dato in input\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# salviamo i dataset su un singolo file\n",
    "\n",
    "pickle_file = \"DeepLearning/data/notMNIST.pickle\"\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'train_dataset': train_dataset,\n",
    "        'train_labels': train_labels,\n",
    "        'valid_dataset': valid_dataset,\n",
    "        'valid_labels': valid_labels,\n",
    "        'test_dataset': test_dataset,\n",
    "        'test_labels': test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle size: 690800441\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBLEMA #4: OVERLAP\n",
    "\n",
    "Valutare la possibilità di overlap (stesse immagini) tra i datasets di training, validation e test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Controllo se sto utilizzando la stessa immagine piu' volte e nel caso la elimino\n",
    "\n",
    "def check_overlaps(images1, images2):\n",
    "    images1.flags.writeable=False\n",
    "    images2.flags.writeable=False\n",
    "    \n",
    "    # Python v2\n",
    "    hash1 = set([hash(image1.data) for image1 in images1])\n",
    "    hash2 = set([hash(image2.data) for image2 in images2])\n",
    "    # Python v3\n",
    "    #hash1 = set([hash(image1.tobytes()) for image1 in images1])\n",
    "    #hash2 = set([hash(image2.tobytes()) for image2 in images2])\n",
    "    \n",
    "    all_overlaps = set.intersection(hash1, hash2)\n",
    "    return all_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlaps between training and test sets:  1144\n"
     ]
    }
   ],
   "source": [
    "r = check_overlaps(train_dataset, test_dataset)    \n",
    "print('Number of overlaps between training and test sets: ', len(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEMA #5\n",
    "\n",
    "Prova ad addestrare un classificatore della libreria ML sklearn \n",
    "\n",
    "Magari trovi una soluzione soddisfacente\n",
    "\n",
    "Ti consiglio di partire da poche istanze di training, es. 50, 100, 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PROBLEMA #6\n",
    "\n",
    "Come mai il data shuffle è così importante?\n",
    "\n",
    "In quali circostanze l'assenza di shuffle può diminuire l'accuratezza? \n",
    "\n",
    "In quali altre circostanze lo shuffle può essere inutile?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
