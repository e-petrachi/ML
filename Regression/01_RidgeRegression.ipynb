{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression \n",
    "\n",
    "Esercizio pratico su dataset \n",
    "\n",
    "Implementazione senza l'utilizzo di GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import numpy as np \n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/Administrator/Development/GraphLabProjects/ML/Regression/data/kc_house_data.csv</pre>"
      ],
      "text/plain": [
       "<pre>Finished parsing file /Users/Administrator/Development/GraphLabProjects/ML/Regression/data/kc_house_data.csv</pre>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.135123 secs.</pre>"
      ],
      "text/plain": [
       "<pre>Parsing completed. Parsed 100 lines in 0.135123 secs.</pre>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\nInferred types from first 100 line(s) of file as \ncolumn_type_hints=[int,str,float,int,float,int,int,float,int,int,int,int,int,int,int,int,int,float,float,int,int]\nIf parsing fails due to incorrect types, you can correct\nthe inferred type list above and pass it to read_csv in\nthe column_type_hints argument\n------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/Administrator/Development/GraphLabProjects/ML/Regression/data/kc_house_data.csv</pre>"
      ],
      "text/plain": [
       "<pre>Finished parsing file /Users/Administrator/Development/GraphLabProjects/ML/Regression/data/kc_house_data.csv</pre>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 21613 lines in 0.144138 secs.</pre>"
      ],
      "text/plain": [
       "<pre>Parsing completed. Parsed 21613 lines in 0.144138 secs.</pre>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = graphlab.SFrame(\"Regression/data/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Implementazione senza GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # aggiungiamo una colonna costante all' SFrame\n",
    "    #aggiungi la colonna costante prima delle feature considerate:\n",
    "    features = ['constant'] + features # combino le due liste\n",
    "    #seleziono le colonne del SFrame contenute all'interno della lista di feature\n",
    "    features_sframe = data_sframe[features]\n",
    "    #Converto feature_sframe in una matrice numpy\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    #assegna la colonna corrispondente all'output a SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    #converto output_sarray in un array_numpy\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    predictions = []\n",
    "    for col in range(feature_matrix.shape[0]):\n",
    "        predictions.append(np.dot(feature_matrix[col,], weights))\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo della derivata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errori, feature):\n",
    "    # Nel caso della feature w[0] la derivata non considera l2_penalty\n",
    "        derivative = 2 * np.dot(errori, feature)\n",
    "        return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discesa del gradiente con Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent_RR(feature_matrix, output, initial_weights, step_size, l2_penalty, tolerance):\n",
    "    converged = False\n",
    "    iterations=0\n",
    "    weights = np.array(initial_weights) # trasformo i pesi iniziali in un array \n",
    "    while not converged and iterations <1000:\n",
    "    #calcolo le predizioni basandomi sulle feature matrix e sui pesi\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        # calcolo gli errori\n",
    "        iterations=iterations+1\n",
    "        errors = predictions - output\n",
    "        gradient_cost=0\n",
    "        #fino a che non ho raggiunto il grado di tolleranza, aggiorno i pesi delle features\n",
    "        for i in range(len(weights)): # loop su ogni feature\n",
    "            # calcolo la derivata per la feature[i]\n",
    "            derivative = feature_derivative(errors,feature_matrix[:,i])\n",
    "            if(i==0):\n",
    "            #sottraggo lo step size * derivata del peso corrente\n",
    "                weights[i] -= step_size * derivative\n",
    "                gradient_cost = gradient_cost + derivative**2\n",
    "            else:\n",
    "                weights[i] = (1-2*step_size*l2_penalty)*weights[i]- step_size*derivative\n",
    "                gradient_cost = gradient_cost+((derivative + 2*l2_penalty*weights[i])**2)\n",
    "                \n",
    "        #calcolo il costo della ridge\n",
    "        gradient_magnitude = sqrt(gradient_cost)\n",
    "        if iterations%10 == 0:\n",
    "            print(\"Iterazione: \", iterations , \" -> \" , gradient_magnitude)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzare gli effetti di L2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "(simple_test_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17384"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_weights = np.array([-45000, 1.])\n",
    "step_size = 1e-11\n",
    "tolerance = 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 100, ' -> ', 12073620.313832276)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 200, ' -> ', 12073545.327394407)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 300, ' -> ', 12073476.443402644)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 400, ' -> ', 12073407.559803462)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 500, ' -> ', 12073338.676597288)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 600, ' -> ', 12073269.793783735)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 700, ' -> ', 12073200.911363998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 800, ' -> ', 12073132.02933677)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 900, ' -> ', 12073063.147702597)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 1000, ' -> ', 12072994.266461425)\n"
     ]
    }
   ],
   "source": [
    "simple_weights_0_penalty = gradient_descent_RR(simple_feature_matrix, \n",
    "                                               output, \n",
    "                                               initial_weights, \n",
    "                                               step_size, \n",
    "                                               0.00000000001, \n",
    "                                               tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 100, ' -> ', 211379678.16315478)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 200, ' -> ', 211378362.26179492)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 300, ' -> ', 211377088.74680555)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 400, ' -> ', 211375815.23949048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 500, ' -> ', 211374541.73984706)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 600, ' -> ', 211373268.24787632)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 700, ' -> ', 211371994.7635771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 800, ' -> ', 211370721.2869528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 900, ' -> ', 211369447.8179985)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 1000, ' -> ', 211368174.35671824)\n"
     ]
    }
   ],
   "source": [
    "simple_weights_high_penalty = gradient_descent_RR(simple_feature_matrix, \n",
    "                                                  output, \n",
    "                                                  initial_weights, \n",
    "                                                  step_size, \n",
    "                                                  1000000000, \n",
    "                                                  tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo del RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98730283193e+15\n"
     ]
    }
   ],
   "source": [
    "predictions_1 = predict_output(simple_test_feature_matrix, initial_weights)\n",
    "residuals_1 = [(predictions_1[i] - test_output[i]) ** 2 for i in range(len(predictions_1))]\n",
    "print sum(residuals_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75353167186e+14\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = predict_output(simple_test_feature_matrix, simple_weights_0_penalty)\n",
    "residuals_2 = [(predictions_2[i] - test_output[i]) ** 2 for i in range(len(predictions_2))]\n",
    "print sum(residuals_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75620251705e+14\n"
     ]
    }
   ],
   "source": [
    "predictions_3 = predict_output(simple_test_feature_matrix, simple_weights_high_penalty)\n",
    "residuals_3 = [(predictions_3[i] - test_output[i]) ** 2 for i in range(len(predictions_3))]\n",
    "print sum(residuals_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-45000.00816622,    281.10845433])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_0_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-44997.77615304,    278.01769821])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights_high_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regression con L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideriamo un modello con 2 feature: `['sqft_living', 'sqft_living15']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'bedrooms'] \n",
    "my_output = 'price'\n",
    "(feature_matrix, train_output) = get_numpy_data(train_data, model_features, my_output)\n",
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo nuovamente i pesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = np.array([0.0,0.0,0.0])\n",
    "step_size = 1e-12\n",
    "tolerance = 18e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 10, ' -> ', 7937755597232.643)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 20, ' -> ', 1091625055434.2767)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 30, ' -> ', 150134049232.293)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 40, ' -> ', 20723418512.329338)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 50, ' -> ', 3359864284.6231213)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 60, ' -> ', 1838475515.7229328)\n"
     ]
    }
   ],
   "source": [
    "multiple_weights_0_penalty = gradient_descent_RR(feature_matrix, \n",
    "                                                 train_output, \n",
    "                                                 initial_weights, \n",
    "                                                 step_size, \n",
    "                                                 0, \n",
    "                                                 tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 10, ' -> ', 7935854707977.612)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 20, ' -> ', 1091097496443.0938)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 30, ' -> ', 150024897597.9844)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 40, ' -> ', 20703304211.96701)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 50, ' -> ', 3355843521.2111254)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterazione: ', 60, ' -> ', 1835988121.4125319)\n"
     ]
    }
   ],
   "source": [
    "multiple_weights_high_penalty = gradient_descent_RR(feature_matrix, \n",
    "                                                    train_output, \n",
    "                                                    initial_weights, \n",
    "                                                    step_size, \n",
    "                                                    10000000, \n",
    "                                                    tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78427328614e+15\n"
     ]
    }
   ],
   "source": [
    "predictions_4 = predict_output(test_feature_matrix, initial_weights)\n",
    "residuals_4 = [(predictions_4[i] - test_output[i]) ** 2 for i in range(len(predictions_4))]\n",
    "print sum(residuals_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75723729916e+14\n"
     ]
    }
   ],
   "source": [
    "predictions_5 = predict_output(test_feature_matrix, multiple_weights_0_penalty)\n",
    "residuals_5 = [(predictions_5[i] - test_output[i]) ** 2 for i in range(len(predictions_5))]\n",
    "print sum(residuals_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75724177402e+14\n"
     ]
    }
   ],
   "source": [
    "predictions_6 = predict_output(test_feature_matrix, multiple_weights_high_penalty)\n",
    "residuals_6 = [(predictions_6[i] - test_output[i]) ** 2 for i in range(len(predictions_6))]\n",
    "print sum(residuals_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376124.379361\n376082.278154\n"
     ]
    }
   ],
   "source": [
    "first = test_data[0]\n",
    "a, b, c= multiple_weights_0_penalty\n",
    "p_0 = a + b * first['sqft_living'] + c * first['bedrooms']\n",
    "print p_0\n",
    "\n",
    "d, e, f = multiple_weights_high_penalty\n",
    "p_high = d + e * first['sqft_living'] + f * first['bedrooms']\n",
    "print p_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.76903118e-02,   2.63023430e+02,   2.62224338e-01])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_weights_0_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.83417666e-02,   2.62993981e+02,   2.65808136e-01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_weights_high_penalty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
